<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bharath G.S &amp; Rita Anjana">
<meta name="dcterms.date" content="2022-10-20">

<title>जिज्ञासा - The Path towards Marketplace recommendations: Part-I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": true,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-R1P14Q05G4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-R1P14Q05G4', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
    .quarto-title-block .quarto-title-banner {
      background: rgb(242, 239, 231);
    }
    </style>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="जिज्ञासा - The Path towards Marketplace recommendations: Part-I">
<meta property="og:description" content="The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.">
<meta property="og:site-name" content="जिज्ञासा">
<meta name="twitter:title" content="जिज्ञासा - The Path towards Marketplace recommendations: Part-I">
<meta name="twitter:description" content="The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.">
<meta name="twitter:creator" content="@maxentlabs">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-sm navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">जिज्ञासा</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://maxentlabs.com"><i class="bi bi-diamond-half" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/maxent-ai"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/maxentlabs"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Path towards Marketplace recommendations: Part-I</h1>
            <p class="subtitle lead">The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.</p>
                                <div class="quarto-categories">
                <div class="quarto-category">ltr</div>
                <div class="quarto-category">recsys</div>
                <div class="quarto-category">optimisation</div>
                <div class="quarto-category">applied-ml</div>
                <div class="quarto-category">marketplace</div>
                <div class="quarto-category">economics</div>
                <div class="quarto-category">notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Bharath G.S &amp; Rita Anjana </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 20, 2022</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="assets/intro.png" class="img-fluid"></p>
<section id="the-backdrop" class="level1">
<h1>The Backdrop</h1>
<p>It took humans less than a decade to reach a level of sophistication to reach a stage where with less than a couple of keystrokes on a phone one could get the most elaborate meal delivered at home. That’s the magic of the internet revolution. In recent times this trend has only gotten sharper and sharper, with the on-demand delivery space heating up, an Indian consumer can receive anything from an egg to the most lavish dinner faster than it takes to respond to a slack message, in fact as of 2022 - you can get most things delivered under 10 minutes!</p>
<p>The implication of this is that the customers do not need to plan anything much in advance and that the time between desire, action, and gratification has shrunk to almost zero. One such Hypothetical unicorn startup in this space is Hyper - Which started just over two years ago and has seen massive growth in a short period.</p>
<p>Hyper is known mainly for its super fast, sub-10-minute delivery of almost anything that one can think of! However, In the past couple of weeks, the sentiment trends around sub-10-minute style deliveries seem to be sharply negative due to various factors especially concerned around the lack of empathy towards Hyper’s delivery partners. What was once a strength seems to be turning into pain for the company and many are asking if we have gone too far.</p>
<p>Within this Hypothetical backdrop where Hyper is reevaluating its business strategy, Hyper’s engineering team set’s forth on a journey to contribute towards its initiative of bringing a bit more balance within the marketplace. This marketplace is not overly user-centric but also is fair for other stakeholders like a delivery partners as well.</p>
<p>Enter recommendation systems, systems that sit at the heart of how most digital marketplaces perform. Most of the digital economies are shaped by these systems - the scale, convenience, and speed of marketplaces like Hyper are enabled by recommendation systems and search engines. Hence, what these systems optimize for and how they behave are of critical importance. Within a marketplace, there are a lot of factors that come into play, and the success of any given marketplace is closely tied to how you match, cater &amp; satisfy the requirements of all the stakeholders like the consumers, suppliers, and more.</p>
<p>In a series of articles, let’s dive deeper into how these systems are designed, and optimized and explore their inner workings and also learn how these systems (or parts of them, to be precise) can be built in practice.</p>
<p>But first, let’s establish a couple of definitions, terms &amp; concepts.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
🧵 Marketplace, marketplace differentiators &amp; superstar economics
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Marketplace</strong>: An intermediary that helps facilitate economic interaction between two or more sets of agents, these have existed since time immemorial as local markets to shopping malls to modern digital experiences like amazon, Flipkart, Swiggy, Instacart, etc - in fact, they are pretty much everywhere.</li>
<li><strong>Differentiating factors of a marketplace</strong>: Marketplaces come in various shapes and sizes, but at a high level they can be differentiated based on Need/Customer coverage (horizontal vs vertical), Participant type (b2b vs b2c), Type of offering (service, goods, information, etc). They can also be differentiated based on control and functionality styles (open, closed, focused, censored, etc), management approach (unmanaged, lite, or fully managed) &amp; lastly their transaction regularity (one-off &amp; repeat transactions).</li>
<li><strong>Superstar economics</strong>: The Phenomenon of superstars, wherein a relatively small number of people earn enormous amounts of money or value of some form and dominate the activities in which they engage.</li>
</ol>
</div>
</div>
</div>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>At the core of any recommendation system, there would be something like a collaborative filtering model (matrix factorization or tensor factorization), latent variable model, neural embeddings-based model, or Neural Collaborative filtering models, and these systems would come in one of these variants - Short vs Long term recommendations, cold start &amp; cohort-based, Multi view and multi-interest models or multi-task recommendations. The most common trend in all these systems usually would be that they all are focused on delivering single user-centric recommendations. These systems were designed to address concerns around user needs, behavior, interests, interactions &amp; personalization. Further, they are measured on user engagement-oriented metrics.</p>
<p>But, caring only about a single user type, might not yield the most optimal outcome especially when there are many stakeholders involved within a platform - aka recommendation systems within a marketplace-type setting could not be designed with a single entity in mind. This is where the need for a recommendation system that caters to different stakeholders with different sets of interests arises.</p>
<p>Hence, Recommendations in marketplaces are multi-sided. Equipped to cater not just to a single user’s (aka buyer) needs, but also the supplier’s needs &amp; most often they also have to consider platform economics within the play. Such a system is usually designed with many objectives in mind - some of these objectives are User expectations, user understanding, supplier exposure, supplier goals, platform objectives, and long-term value.</p>
<p>Now let’s further look into these different stakeholders, their objectives &amp; the interplay between these objectives that usually arise within this ecosystem.</p>
<section id="stakeholders-objectives-the-objective-interplay" class="level2">
<h2 class="anchored" data-anchor-id="stakeholders-objectives-the-objective-interplay">Stakeholders, Objectives &amp; the Objective interplay</h2>
<p>In a multi-sided system with multiple objectives often the objectives interact and behave in different manners. At a high level, you could categorize the different types of these interplay as follows:</p>
<ul>
<li><strong>Correlated</strong> : Optimising for one objective helps the other.</li>
<li><strong>Neutral</strong>: Optimising for one does not impact the other</li>
<li><strong>Anti Correlated</strong>: Optimising for one hurts the other</li>
</ul>
<p>Consider the example of our Hypothetical on-demand delivery startup Hyper, which is a three-sided marketplace - i.e it has three sets of stakeholders with different motivations &amp; objectives.</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 36%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Stakeholder</th>
<th>Needs/Motivations</th>
<th>Potential Objectives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>End User</td>
<td>Wants to order something from local partner shops.</td>
<td><ul>
<li>Quick delivery</li>
<li>Best price</li>
<li>Reliable merchants</li>
<li>Fresh items</li>
</ul></td>
</tr>
<tr class="even">
<td>Merchants</td>
<td>Provide online visibility and find customers.</td>
<td><ul>
<li>Matching quality</li>
<li>Exposure</li>
<li>Minimise wastage</li>
</ul></td>
</tr>
<tr class="odd">
<td>Delivery Partners</td>
<td>Earn a stable livelihood.</td>
<td><ul>
<li>Regularity in jobs</li>
<li>Earnings per partner</li>
<li>Efficient drop location planning</li>
</ul></td>
</tr>
</tbody>
</table>
<p>As we see above each entity has a unique set of potential objectives one could optimise the recommendation system for &amp; this has to be done in a deliberate and careful way or it might result in undesired outcomes.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
🧵 Superstar economics and towards a fair marketplace
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Researchers from Microsoft &amp; Spotify found out that:</p>
<blockquote class="blockquote">
<p>Recommendation systems in general suffer from what is called as an inherent problem of “superstar economics”: rankings have a top and a tail end, not just for popularity, but also for relevance. In an attempt to maximize user satisfaction, recommender system optimize for relevance. This inadvertently leads to lock-in of popular and relevant suppliers, especially for users who want to minimize the effort required to interact with the system. A major side-effect of the superstar economics is the impedance to suppliers on the tail-end of the spectrum, who struggle to attract consumers, given the low exposure, and thus, are not satisfied with the marketplace. Indeed, to continue to attract more suppliers to the platform, marketplaces face an interesting problem of optimizing their models for supplier exposure, and visibility. Indeed, the suppliers (e.g.&nbsp;retailers, artists) would want a fair opportunity to be presented to the users.</p>
</blockquote>
<p>Read more about this in <a href="https://dl.acm.org/doi/10.1145/3269206.3272027">Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness &amp; Satisfaction in Recommendation Systems</a></p>
</div>
</div>
</div>
<p>In short, what a system optimises for is super important &amp; in general, it needs to look for a balance while optimising for various objectives.</p>
<p>Before we proceed further on the track of optimising for multiple objectives (or multiple objective optimisation) - let us quickly visit how most modern recommendation systems look like &amp; also do a quick recap of how one builds a model for ranking (aka Learning to rank) &amp; some key metrics used for measuring these systems.</p>
</section>
</section>
<section id="a-quick-recap-on-modern-recsys" class="level1">
<h1>A Quick Recap on modern recsys</h1>
<p><img src="assets/recsys-wn.png" class="img-fluid"></p>
<p>Over the past few years, a common and a central design pattern has emerged around how most industrial recommendation systems are designed. If one were to summarise this design pattern, it would appear as described in the above figure - consisting of 4 stages. Let us take a brief look at the functionality of these four stages:</p>
<section id="candidate-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="candidate-retrieval">Candidate retrieval</h2>
<p>The Retrieval &amp; filtering stages usually are collectively refered to as candidate generation, this is a fast but coarse step which essentially narrows down the search space of items from millions of candidates for a given query to soemthing in order of 100s.</p>
<p>This is often achieved by an initial retrieval with some form of matching between the query and the catalog usually via an ANN, Graph based approach or some form of decision trees. Followed by a filtering stage, where invalid candidates are removed from the initial retrieval before passing onto the next stages.</p>
</section>
<section id="ranking" class="level2">
<h2 class="anchored" data-anchor-id="ranking">Ranking</h2>
<p>At this phase we further narrow down the initial set of items into a much smaller list that would be presented to the user. This is a slow but more precise operation - this stage is usually modelled as an LTR task or a classification task. Further, sometimes it’s followed by an ordering stage which handles various types of business logic to reorder/sort the final list of items. Some common examples of these business logic include: organising recommendations to fit genre distributions in streaming services or promoting certain segments of sellers as in case of ecommerce.</p>
<div class="callout-tip callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
📝 Suggested reading
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most Production recommendation systems are indeed complex in nature, but the above pattern which was conceptulised at Nvidea by <a href="https://twitter.com/Even_Oldridge"><span class="citation" data-cites="Even_Oldridge">@Even_Oldridge</span></a> &amp; <a href="https://twitter.com/karlhigley"><span class="citation" data-cites="karlhigley">@karlhigley</span></a> sort of provides a good overview of how these systems are designed &amp; to read a bit more on this, refer to <a href="https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e">Recommender Systems not just recommender models</a> article &amp; also read <a href="https://eugeneyan.com/writing/system-design-for-discovery/">system-design-for-discovery</a> from <a href="https://twitter.com/eugeneyan"><span class="citation" data-cites="eugeneyan">@eugeneyan</span></a> where he summarises this design pattern in depth and points to multiple examples from industry that follow this pattern.</p>
</div>
</div>
</section>
</section>
<section id="a-quick-recap-on-learning-to-rank" class="level1">
<h1>A Quick Recap on Learning to Rank</h1>
<p>Learning to rank (LTR) refers to a class of ML techniques for training a model to solve the task of ranking a set of items. Usually this is formulated as a supervised or sometimes semi-supervised task.</p>
<p>Generally, this means we try to learn a function <span class="math inline">\(f(q, D)\)</span> given a query <span class="math inline">\(q\)</span> &amp; a list of documents <span class="math inline">\(D\)</span> to predict the order/rank of the documents within this list. Depending on how the loss function is formulated in the underlying task, any LTR algorithm can be classified into 3 distinct categories:</p>
<ol type="1">
<li>Pointwise method</li>
<li>Pairwise method</li>
<li>Listwise method</li>
</ol>
<section id="ranking-task" class="level2">
<h2 class="anchored" data-anchor-id="ranking-task">Ranking Task</h2>
<p>Given a query <span class="math inline">\(q\)</span>, and a set of <span class="math inline">\(n\)</span> documents <span class="math inline">\(D=d_1,d_2,...,dn\)</span>, we’d like to learn a function <span class="math inline">\(f\)</span> such that <span class="math inline">\(f(q, D)\)</span> will predict the relevance of any given document associated with a query.</p>
</section>
<section id="pointwise-method" class="level2">
<h2 class="anchored" data-anchor-id="pointwise-method">Pointwise method</h2>
<p>In pointwise method, the above ranking task is re-formulated as a standard classification/regression task. The function to be learned <span class="math inline">\(f(q, D)\)</span> is simplified as <span class="math inline">\(f(q, d_i)\)</span> i.e the relevance of each document given a query is scored independently.</p>
<p>For instance, if we have two queries associated with 2 and 3 resulting matched documents:</p>
<ol type="1">
<li><span class="math inline">\(q_1 \to d_1, d_2\)</span></li>
<li><span class="math inline">\(q_2 \to d_3, d_4, d_5\)</span></li>
</ol>
<p>Then the training data <span class="math inline">\(x_i\)</span> in a pointwise method will essentially be every query-document pair as follows:</p>
<ol type="1">
<li><span class="math inline">\(x_1 : q_1, d_1\)</span></li>
<li><span class="math inline">\(x_2 : q_1, d_2\)</span></li>
<li><span class="math inline">\(x_3 : q_2, d_3\)</span></li>
<li><span class="math inline">\(x_4 : q_2, d_4\)</span></li>
<li><span class="math inline">\(x_5 : q_2, d_5\)</span></li>
</ol>
<p>Since each document is scored independently with the absolute relevance as the target label, the task is no different from any standard classification or regression task. As such any standard ml algorithms can be leveraged in this setting.</p>
</section>
<section id="pairwise-method" class="level2">
<h2 class="anchored" data-anchor-id="pairwise-method">Pairwise method</h2>
<p>In pairwise method, the goal is to learn a pointwise scoring function <span class="math inline">\(f(q, d_i)\)</span> similar to a pointwise formulation. However, the key difference arises in how the training data is consructed - where we take pairs of documents within the same query as training samples.</p>
<ol type="1">
<li><span class="math inline">\(x_1 \to q_1, (d_1, d_2)\)</span></li>
<li><span class="math inline">\(x_2 \to q_1, (d_3, d_4)\)</span></li>
<li><span class="math inline">\(x_3 \to q_1, (d_3, d_5)\)</span></li>
<li><span class="math inline">\(x_4 \to q_1, (d_4, d_5)\)</span></li>
</ol>
<p>In this setting, a new set of pairwise binary labels are derived, by comapring the individual relevance score in each pair. For example, given the first query <span class="math inline">\(q_1\)</span>, if <span class="math inline">\(y_1==\)</span> (i.e.. an irrelevant document) for <span class="math inline">\(d_1\)</span> &amp; <span class="math inline">\(y_2=3\)</span> (i.e.. a Highly relevant document) for <span class="math inline">\(d_2\)</span> then we can create a new label <span class="math inline">\(y_1&lt;y_2\)</span> for the pair of docs <span class="math inline">\((d_1, d_2)\)</span> - by doing so we have essentially converted this back to a binary classification task again.</p>
<p>Now in order to learn the function <span class="math inline">\(f(q, d_i)\)</span> which is still pointwise, but in a pairwise manner, we model the difference in scores probablistically as follows:</p>
<p><span class="math display">\[P(i&gt;j) \equiv \frac{1}{1+exp^{-(s_i - s_j)}}\]</span></p>
<p>i.e, if document <span class="math inline">\(i\)</span> is better matched than document <span class="math inline">\(j\)</span> (denoted as <span class="math inline">\(i&gt;j\)</span>), then the probability of the scoring function to have scored <span class="math inline">\(f(q, d_i) = S_i\)</span> should be close to 1. In other words, the model is trying to learn, given a query, how to score a pair of documents such that a more relevant document would be scored higher.</p>
</section>
<section id="listwise-method" class="level2">
<h2 class="anchored" data-anchor-id="listwise-method">Listwise method</h2>
<p>Listwise methods, solve the problem of ranking by learning to score the entire list jointly and they do so via two main sub techniques:</p>
<ul>
<li>Direct optimization of IR measures such as NDCG.(Eg: SoftRank, AdaRank).</li>
<li>Minimize a loss function that is defined based on understanding the unique properties of the kind of ranking you are trying to achieve. (E.g. ListNet, ListMLE).</li>
</ul>
<p>Let’s do a quick review of one of these approaches:</p>
<p>Consider ListNet, Which is based on the concept of permutation probability of a list of items. In this case we assume there is a pointwise scoring function <span class="math inline">\(f(q,di)\)</span> used to score and rank a given list of items. But instead of modeling the probability as a pairwise comparison using scoring difference, we model the probability of the entire list of results. In this setting our documents and query dataset would appear like this:</p>
<ol type="1">
<li><span class="math inline">\(x_1 : q_1, (d_1, d_2)\)</span></li>
<li><span class="math inline">\(x_2 : q_2, (d_3, d_4, d_5)\)</span></li>
</ol>
<p>First let’s look at the Permutation probability. Let’s denote <span class="math inline">\(π\)</span> as a specific permutation of a given list of length <span class="math inline">\(n\)</span>, <span class="math inline">\(\Theta (s_i) = f(q, d_i)\)</span> as any increasing function of scoring <span class="math inline">\(s_i\)</span> given a query <span class="math inline">\(q\)</span> and a document <span class="math inline">\(i\)</span>. The probability of having a permutation <span class="math inline">\(π\)</span> can be written as follows:</p>
<p><span class="math display">\[P(\pi) = \prod_{i=1}^n \frac{\phi(s_i)}{\sum_{k=i}^n\phi(s_k)}\]</span></p>
<p>To illustrate consider a list of 3 items, then the probability of returning the permutation <span class="math inline">\(s_1\)</span>,<span class="math inline">\(s_2\)</span>,<span class="math inline">\(s_3\)</span> is calculated as follows:</p>
<p><span class="math display">\[P(\pi = \{s_1, s_2, s_3\}) = \frac{\phi(s_1)}{\phi(s_1) + \phi(s_2) + \phi(s_3)} \cdot \frac{\phi(s_2)}{\phi(s_2) + \phi(s_3)} \cdot \frac{\phi(s_3)}{\phi(s_3)}\]</span></p>
<p>Due to computational complexity, ListNet simplies the problem by looking at only the top-one probability of a given item. The top-one probability of object i equals the sum of the permutation probabilities of permutations in which object i is ranked on the top. Indeed, the top-one probability of object i can be written as:</p>
<p><span class="math display">\[P(i) = \frac{\phi(s_i)}{\sum_{k=1}^n \phi(s_k)}\]</span></p>
<p>Given any two list of items represented by top-one probabilities, we can now measure the difference between them using cross entropy. Then we can use an ml algorithm which minimises that cross entropy. The choice of function <span class="math inline">\(ϕ(⋅)\)</span>, can be as simple as just an exponential function. When <span class="math inline">\(ϕ(⋅)\)</span> is expotential and the list length is two, the solution basically reduces to a pairwise method as described earlier.</p>
<p>With that brief introduction out of the way, let’s also quickly look at the advantages and disadvantages of each of these approaches:</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 47%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pointwise</td>
<td><ul>
<li>Simplicity, Any standard ML models can be applied without any changes.</li>
</ul></td>
<td><ul>
<li>The results can be often sub-optimal due to not utilizing the full information of the entire list of matching documents for each query.</li>
<li>This requires explicit labels while constructing the dataset, and can be quite expensive.</li>
</ul></td>
</tr>
<tr class="even">
<td>Pairwise</td>
<td><ul>
<li>We don’t need explicit labels, Only pairwise preferences are required.</li>
<li>The model learns how to rank directly, even though its a pairwise setting, but in theory it can approximate the performance of a general ranking task.</li>
</ul></td>
<td><ul>
<li>The Core Scoring mechanism is still pointwise. Hence, that relative information in the feature space among different documents given the same query is still not fully leveraged.</li>
</ul></td>
</tr>
<tr class="odd">
<td>Listwise</td>
<td><ul>
<li>Theoretically this is a good solution for a ranking task.</li>
</ul></td>
<td><ul>
<li>Costly to compute in its theoretical form and hence several approximations are used in practice.</li>
<li>Scoring function is still pointwise, which could be sub-optimal.</li>
</ul></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="a-quick-recap-on-ranking-evaluation-metrics" class="level1">
<h1>A Quick Recap on Ranking Evaluation metrics</h1>
<p>Over the years, there have been several metrics which have been proposed and widely used for evaluating a ranking model. If we were to summarise them and list the most popular ones it boils down to this:</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Metric Type</th>
<th>Metric</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binary Relevance</td>
<td>Mean Average Precision (MAP)</td>
</tr>
<tr class="even">
<td>Binary Relevance</td>
<td>Mean Reciprocal Rank (MRR)</td>
</tr>
<tr class="odd">
<td>Graded Relevance</td>
<td>Normalized Discounted Cumulative Gain (NDCG)</td>
</tr>
<tr class="even">
<td>Graded Relevance</td>
<td>Expected Reciprocal Rank (ERR)</td>
</tr>
</tbody>
</table>
<p>In general, binary metrics only consider relevant v.s. irrelevant, while graded metrics also consider the ranking among relevant items. The degree of relevancy matters in this case when scoring a list of items.</p>
<section id="mean-average-precision-map" class="level2">
<h2 class="anchored" data-anchor-id="mean-average-precision-map">Mean Average Precision (MAP)</h2>
<p>MAP is a measure based on binary label of relevancy. To compute this first we define precision at k for a given query <span class="math inline">\(P@k(q)\)</span> as:</p>
<p><span class="math display">\[P@k(q) \equiv \frac{\sum_{i=1}^k r_i}{k}\]</span></p>
<p>for an ordered list of prediction <span class="math inline">\(r_i\)</span> for all <span class="math inline">\(k\)</span> items. <span class="math inline">\(ri=1\)</span> if it is relevant and 0 otherwise.Then we define the average precision given a query <span class="math inline">\(AP(q)\)</span> at <span class="math inline">\(k\)</span> items as:</p>
<p><span class="math display">\[AP(q)@k \equiv \frac{1}{\sum_{i=1}^k r_i} \sum_{i=1}^k P@i(q) \times r_i\]</span></p>
<p>Mean Average Precision is just the mean of <span class="math inline">\(AP(q)\)</span> for all queries:</p>
<p><span class="math display">\[MAP \equiv \frac{\sum_{q=1}^Q AP(q)}{Q}\]</span></p>
<p>Also, MAP is an order sensitive metric because of the term <span class="math inline">\(r_i\)</span> in the calculation of AP. It is essentially taking the average of precision at each ranking position and penalizing the precision at positions with irrelevant item by strcitly setting them to zeroes.</p>
<p>Here is a simple example for computing MAP:</p>
<p><img src="assets/map.jpeg" class="img-fluid"></p>
</section>
<section id="mean-reciprocal-rank-mrr-expected-reciprocal-rank-err" class="level2">
<h2 class="anchored" data-anchor-id="mean-reciprocal-rank-mrr-expected-reciprocal-rank-err">Mean Reciprocal Rank (MRR) &amp; Expected Reciprocal Rank (ERR)</h2>
<p>Reciprocal rank metrics focus mainly on the first correctly predicted relevant item in a list. Given a list of items, and say <span class="math inline">\(r_i\)</span> is the rank of the highest ranking relevant item &amp; if the the 2nd item is the first relevant item in the list, then the reciprocal rank for this query would be <span class="math inline">\(\frac{1}{2}\)</span>. By extension, each query will have a reciprocal rank. Hence, Mean reciprocal rank is essentially the average of reciprocal rank for all the queries, which would be represented as follows:</p>
<p><span class="math display">\[MRR \equiv \frac{1}{Q} \sum_{i=1}^Q\frac{1}{r_i}\]</span></p>
<p>Expected reciprocal rank tries to quantify how useful a document at rank <span class="math inline">\(i\)</span> conditioned on the degree of relevance of documents at rank less than <span class="math inline">\(i\)</span> are. The intution behind this is based on the empirical findings from web search task, that the likelihood a user will examine the document at rank <span class="math inline">\(i\)</span> is dependent on how satisfied the user was with previously observed documents in the list.</p>
<p>Lets assume the probability of a user finding the result is satisfied at position <span class="math inline">\(i\)</span> in a list of items is denoted as <span class="math inline">\(R_i\)</span> &amp; the likelihood of a session for which the user is satisfied and stops at position <span class="math inline">\(r\)</span> is: <span class="math display">\[\prod_{i=1}^{r-1}(1 - R_i)R_r\]</span></p>
<p>Now we can model <span class="math inline">\(R_i\)</span> such that it is an increasing function of relevance:</p>
<p><span class="math display">\[R = R(g) \equiv \frac{2^g - 1}{2^{g_{max}}}\]</span></p>
<p>where <span class="math inline">\(g\)</span> is the graded relevance such that <span class="math inline">\(g \in \{0, 1, ..., g_{max}\}\)</span> &amp; <span class="math inline">\(g = 0\)</span> implies an irrelevant document and <span class="math inline">\(g = g_{max}\)</span> implies a relevant document.</p>
<p>Now we can define ERR as follows:</p>
<p><span class="math display">\[ERR \equiv \sum_{r=1}^n\frac{1}{r}R_r\prod_{i=1}^{r-1}(1-R_i)\]</span></p>
<p>Here <span class="math inline">\(\frac{1}{r}\)</span> is treated as a utility function <span class="math inline">\(\tau(r)\)</span> that satisfies <span class="math inline">\(\tau(1) = 1\)</span> and <span class="math inline">\(\tau(r) \rightarrow 0\)</span> as <span class="math inline">\(r \rightarrow \infty\)</span>.</p>
<p>Note that ERR is a metric on a list with a single query, To evaluate results from multiple queries, we will need to further average ERRs among queries.</p>
<p>Here is a simple example for computing MRR:</p>
<p><img src="assets/mrr.jpeg" class="img-fluid"></p>
</section>
<section id="normalized-discounted-cumulative-gain-ndcg" class="level2">
<h2 class="anchored" data-anchor-id="normalized-discounted-cumulative-gain-ndcg">Normalized Discounted Cumulative Gain (NDCG)</h2>
<p>Normalized Discounted Cumulative Gain (NDCG) is one of the most popular metric for measuring the quality of a set of ranked items in search or recommendations. If we were to break the assumptions made by this metric in simple terms, it would be as follows:</p>
<ol type="1">
<li>Cumulative Gain: Very relevant items are more useful than somewhat relevant items which are more useful than completely irrelevant items.</li>
<li>Discounting: Relevant items are more useful when they appear earlier in a list of ranked items.</li>
<li>Normalization: The result of the ranking should be irrelevant to the query performed.</li>
</ol>
<p>Let’s define Discounted Cumulative Gain at position <span class="math inline">\(k\)</span> as follows:</p>
<p><span class="math display">\[DCG@k \equiv \sum_{i=1}^k\frac{2^{l_i} - 1}{log_2(i + 1)}\]</span></p>
<p>where <span class="math inline">\(l_i\)</span> is the grading of relevance at rank <span class="math inline">\(i\)</span>. Intutively, the numerator is simply an increasing function of relevance, the more relevant the higher. This is the <em>gain</em> from each item. The denominator is a decreasing function of ranking position, this is the <em>discounted</em> component of the metric. Collectively, higher relevance gains more score, but the lower it is ranked the higher also the discount. Essentially, the metric will prefer higher relevant item to be ranked higher, which is the desired outcome.</p>
<p>NDCG is then defined as:</p>
<p><span class="math display">\[NDCG@k = \frac{DCG@k}{IDCG@k}\]</span></p>
<p>where <span class="math inline">\(IDCG@k\)</span> is the <em>Ideal</em> DCG@k given the result. DCG@k is calculated by sorting the given list of items by its true relevance labels. and IDCG@k is the maximum possible DCG@K value one can get given a ranked list of items.</p>
<p>Here is a simple example for computing NDCG:</p>
<p><img src="assets/ndcg.jpeg" class="img-fluid"></p>
</section>
</section>
<section id="learning-to-rank-with-multiple-objectives" class="level1">
<h1>Learning to rank with Multiple Objectives</h1>
<section id="moo---the-what-the-why-the-how." class="level2">
<h2 class="anchored" data-anchor-id="moo---the-what-the-why-the-how.">MOO - The What, The Why &amp; The How.</h2>
<p>After that long detour, let’s now look into Multiple Objective Optimisation applied to Ranking problem within a marketplace type setting involving multiple stakeholders. Let’s do so with a simple illustrative example that involves similar item recommendations. Specifically, let’s understand Why this is needed first.</p>
<p>Picture this, A User has browsed and explored a bunch of different red shirts that he’s planning to buy, and on one such open tab we’ve got a shirt that he’s closely examining. Now, the recommendation system in the backend is also generating a bunch of similar shirts that he might be interested in, further let’s say the recommendation system is optimising for two different objectives - firstly, to show not just relevant but also personalised shirts similar to his style, based on his interaction history that he might explore further &amp; perhaps buy. Secondly, the platform also wants to make sure it’s making a good profit on each sales that the recommendation system generates/leads to - hence wants to also promote shirts with a good margin. How would we do this?</p>
<p>Let’s start by defining our objectives:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Objective I</th>
<th>Objective II</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Personalisation</td>
<td>Price Margin</td>
</tr>
</tbody>
</table>
<p>Let’s also say the item options available to us to be displayed (let’s focus on finding the top-1 item at the moment.) if plotted on a graph look something like this:</p>
<p><img src="assets/pareto-samples.png" class="img-fluid"></p>
<p>Now, essentially we want to maximise profit margin but also we want to maximise for highly personalised &amp; relevant shirt. If we were to solve this from a lens of single objectve optimisation two scenarios would arise:</p>
<ol type="1">
<li><p>Case-I: Applying 1D Optimisation to objective I followed by optimising for objective II, i.e First we can find Highly Personalised shirts and then search for the shirt that also provides maximum margin.</p></li>
<li><p>Case-II: Applying 1D Optimisation to objective II followed by optimising for objective I, i.e First we can find High Profit margin shirts and then search for the ones which are also Highly Personalised &amp; relevant for the user’s style.</p></li>
</ol>
<p>For a simple and better understanding of the concept, assume that someone is trying to find the best red shirt from both the perspectives manually in a physical store, and let’s further also assume its a dark room.</p>
<section id="case-i-highly-personalised-high-profit-margin" class="level3">
<h3 class="anchored" data-anchor-id="case-i-highly-personalised-high-profit-margin">Case I : Highly Personalised &amp; High Profit margin</h3>
<p><img src="assets/relevance-first.png" class="img-fluid"></p>
<ol type="1">
<li>So, in this case the solver turns the torch on towards the relevance axis and discovers <span class="math inline">\(T5\)</span> as the most suitable candidate.</li>
<li>Now from this point the solver turns towards the profit axis and turns the torch on and discovers <span class="math inline">\(T6\)</span>.</li>
</ol>
</section>
<section id="case-ii-high-profit-margin-high-personalisation" class="level3">
<h3 class="anchored" data-anchor-id="case-ii-high-profit-margin-high-personalisation">Case II : High Profit margin &amp; High Personalisation</h3>
<p><img src="assets/profit-first.png" class="img-fluid"></p>
<ol type="1">
<li>In this case the solver turns the torch on towards the profit axis and discovers <span class="math inline">\(T3\)</span> as the best candidate.</li>
<li>Now from this point the solver turns towards the relevance axis and turns the torch on and discovers <span class="math inline">\(T4\)</span>.</li>
</ol>
<p>What do we have as of now:</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 33%">
<col style="width: 32%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Process</th>
<th>1st Optimization Objective</th>
<th>2nd Optimization Objective</th>
<th>Optimal Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Personalisation</td>
<td>Profit Margin</td>
<td><span class="math inline">\(T6\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td>Profit Margin</td>
<td>Personalisation</td>
<td><span class="math inline">\(T4\)</span></td>
</tr>
</tbody>
</table>
<p>So, that seems odd. there’s multiple solutions depending on what we actually want to achieve. If, we want to optimise for both and find the best solution, Going about in the above method seems to be not the best way. This is why, we need to optimise for finding solutions for both objectives collectively and the method or set of optimisation methods for it is called <em>Multiple Objective Optimization</em>.</p>
<p>Let’s deine what MOO is &amp; try to understand some other associated important concepts first, before we see how these are applied to ranking task in industry.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Basic Concepts - Defining the MOO Problem, Pareto Optimum &amp; Pareto Frontier
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>MOO</strong>: Optimization that involves identifying the values of decision (or free) variables that generate the maximum or minimum of one or more objectives. In most engineering problems, there may exist multiple, conflicting objectives and solving the optimization problems is not trivial or may not be even feasible sometimes. One way to formulate this is as follows:</p>
<p>Given <span class="math inline">\(m\)</span> inequality constraints &amp; <span class="math inline">\(p\)</span> equality constraints identify a vector <span class="math inline">\(\bar{x}^*_n = [x^*_1, x^*_2,...,x^*_n]^T\)</span> that optimizes</p>
<p><span class="math display">\[\bar{f}_k(\bar{x}_n) = [o_1(\bar{x}_n), o_2(\bar{x}_n),..., o_k(\bar{x}_n)]^T\]</span></p>
<p>such that</p>
<p><span class="math display">\[g_i(\bar{x}_n) ≥ 0, i = 1, 2, . . . , m\]</span></p>
<p><span class="math display">\[h_i( \bar{x}_n) = 0, i = 1, 2, . . . , p\]</span></p>
<p>where <span class="math inline">\(\bar{x}_n = [x_1, x_2, . . . , x_n]^T\)</span> is a vector of <span class="math inline">\(n\)</span> decision variables. The constraints determine the “feasible region” <span class="math inline">\(F\)</span> and any point <span class="math inline">\(\bar{x}_n ∈ F\)</span> gives a “feasible solution” where <span class="math inline">\(g_i( \bar{x}_n)\)</span> and <span class="math inline">\(h_i( \bar{x}_n)\)</span> are the constraints imposed on decision variables. The vector function <span class="math inline">\(\bar{f}_k(\bar{x}_n)\)</span> above is a set of <span class="math inline">\(k\)</span> objective functions, <span class="math inline">\(o_i(\bar{x}_n)\)</span> for <span class="math inline">\(i = 1, · · · , k\)</span>, representing k non-commensurable criteria.</p>
<p><strong>Pareto Optimum</strong>: A point <span class="math inline">\(\bar{x}^∗\)</span> is “Pareto optimal” (for minimisation task) if the following holds for every <span class="math inline">\(\bar{x}_n ∈ F\)</span></p>
<p><span class="math display">\[\bar{f}_k(\bar{x}^*_n) ≤  \bar{f}_k( \bar{x}_n)\]</span></p>
<p>where <span class="math inline">\(\bar{f}_k(\bar{x}_n) = [o_1(\bar{x}_n), o_2(\bar{x}_n),..., o_k(\bar{x}_n)]^T\)</span>, <span class="math inline">\(\bar{f}^*_k(\bar{x}^*_n) = [o_1(\bar{x}^*_n), o_2(\bar{x}^*_n),..., o_k(\bar{x}^*_n)]^T\)</span></p>
<p>Pareto optimality gives a set of nondominated solutions. A feasible solution <span class="math inline">\(x\)</span> is called “weakly nondominated” if there is no <span class="math inline">\(y ∈ F\)</span> , such that <span class="math inline">\(o_i(y) &lt; o_i(x)\)</span> for all <span class="math inline">\(i = 1, 2, ..., k\)</span>. This means that there is no other feasible solution that can strictly dominate <span class="math inline">\(x\)</span>. A feasible solution <span class="math inline">\(x\)</span> is called “strongly nondominated” if there is no <span class="math inline">\(y ∈ F\)</span> , such that <span class="math inline">\(o_i(y) ≤ o_i(x)\)</span> for all <span class="math inline">\(i = 1, 2, ...k\)</span>, and <span class="math inline">\(o_i(y) &lt; o_i(x)\)</span> for at least one <span class="math inline">\(i\)</span>. This means that there is no other feasible solution that can improve some objectives without worsening at least one other objective. If <span class="math inline">\(x\)</span> is “strongly nondominated”, it is also “weakly nondominated”.</p>
<p><strong>Pareto Frontier</strong>: A set (of feasible solutions) that is Pareto efficient is called the Pareto frontier, Pareto set, or Pareto front. The optimal solutions can be determined based on the tradeoffs within this set based on a designer’s decisions for acceptable performance.</p>
<p>read more on this from <a href="https://people.cs.vt.edu/~irchen/ps/Cho-ieeecst17.pdf">A Survey on Modeling and Optimizing Multi-Objective Systems</a></p>
</div>
</div>
</div>
</section>
</section>
<section id="popular-methods-applied-to-ltr-setting." class="level2">
<h2 class="anchored" data-anchor-id="popular-methods-applied-to-ltr-setting.">Popular methods applied to LTR Setting. 🚧</h2>
</section>
<section id="examples-in-wild" class="level2">
<h2 class="anchored" data-anchor-id="examples-in-wild">Examples in Wild 🚧</h2>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion 🚧</h1>
</section>
<section id="acknowledgement" class="level1">
<h1>Acknowledgement 🚧</h1>
</section>
<section id="reference" class="level1">
<h1>Reference 🚧</h1>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>