<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bharath G.S &amp; Rita Anjana">
<meta name="dcterms.date" content="2022-10-20">

<title>‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡§æ - The Path towards Marketplace recommendations: Part-I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": true,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-R1P14Q05G4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-R1P14Q05G4', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>
    .quarto-title-block .quarto-title-banner {
      background: rgb(242, 239, 231);
    }
    </style>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡§æ - The Path towards Marketplace recommendations: Part-I">
<meta property="og:description" content="The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.">
<meta property="og:site-name" content="‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡§æ">
<meta name="twitter:title" content="‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡§æ - The Path towards Marketplace recommendations: Part-I">
<meta name="twitter:description" content="The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.">
<meta name="twitter:creator" content="@maxentlabs">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-sm navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡§æ</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://maxentlabs.com"><i class="bi bi-diamond-half" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/maxent-ai"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/maxentlabs"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Path towards Marketplace recommendations: Part-I</h1>
            <p class="subtitle lead">The Foundation: A Notes on Recsys, LTR, Ranking Evaluation metrics &amp; Multi Objective Ranking in practice.</p>
                                <div class="quarto-categories">
                <div class="quarto-category">ltr</div>
                <div class="quarto-category">recsys</div>
                <div class="quarto-category">optimisation</div>
                <div class="quarto-category">applied-ml</div>
                <div class="quarto-category">marketplace</div>
                <div class="quarto-category">economics</div>
                <div class="quarto-category">notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Bharath G.S &amp; Rita Anjana </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 20, 2022</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="assets/intro.png" class="img-fluid"></p>
<section id="the-backdrop" class="level1">
<h1>The Backdrop</h1>
<p>It took humans less than a decade to reach a level of sophistication to reach a stage where with less than a couple of keystrokes on a phone one could get the most elaborate meal delivered at home. That‚Äôs the magic of the internet revolution. In recent times this trend has only gotten sharper and sharper, with the on-demand delivery space heating up, an Indian consumer can receive anything from an egg to the most lavish dinner faster than it takes to respond to a slack message.</p>
<p>In fact, as of 2022 you can get most things delivered under 10 minutes! The implication of this is that the customers do not need to plan anything much in advance and that the time between desire, action, and gratification has shrunk to almost zero. One such Hypothetical unicorn startup in this space is Hyper - Which started over two years ago and has seen massive growth in a short period. Hyper is known mainly for its super fast, sub-10-minute delivery of almost anything that one can think. However, In the past couple of weeks, the sentiment trends around sub-10-minute style deliveries has been sharply negative due to various factors. Especially concerned around the lack of empathy towards Hyper‚Äôs delivery partners. What was once a strength seems to be turning into pain for the company. Many are asking if we have gone too far.</p>
<p>Within this Hypothetical backdrop where Hyper is reevaluating its business strategy, Hyper‚Äôs engineering team set‚Äôs forth on a journey to contribute towards its initiative of bringing a bit more balance within the marketplace. This marketplace is not overly user-centric but is also fair for other stakeholders like delivery partners. Enter recommendation systems, systems that sit at the heart of how most digital marketplaces perform. Most digital economies are shaped by these systems. The scale, convenience, and speed of marketplaces like Hyper are enabled by recommendation systems and search engines. Hence, what these systems optimize for and how they behave are of critical importance. Within a marketplace, multiple factors come into play, and the success of any given marketplace is closely tied to how you match, cater &amp; satisfy the requirements of all the stakeholders like the consumers, suppliers, and more. In a series of articles, let‚Äôs dive deeper into how these systems are designed, optimized and explore the inner workings and learn how some parts of these systems are built in practice.</p>
<p>But first, let‚Äôs establish a couple of definitions, terms &amp; concepts.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
üßµ Marketplace, marketplace differentiators &amp; superstar economics
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Marketplace</strong>: An intermediary that helps facilitate economic interaction between two or more sets of agents, these have existed since time immemorial as local markets to shopping malls to modern digital experiences like amazon, Flipkart, Swiggy, Instacart, etc - in fact, they are pretty much everywhere.</li>
<li><strong>Differentiating factors of a marketplace</strong>: Marketplaces come in various shapes and sizes, but at a high level they can be differentiated based on Need/Customer coverage (horizontal vs vertical), Participant type (b2b vs b2c), Type of offering (service, goods, information, etc). They can also be differentiated based on control and functionality styles (open, closed, focused, censored, etc), management approach (unmanaged, lite, or fully managed) &amp; lastly their transaction regularity (one-off &amp; repeat transactions).</li>
<li><strong>Superstar economics</strong>: The Phenomenon of superstars, wherein a relatively small number of people earn enormous amounts of money or value of some form and dominate the activities in which they engage.</li>
</ol>
</div>
</div>
</div>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>At the core of any recommendation system, there would be something like a collaborative filtering model (matrix factorization or tensor factorization), latent variable model, neural embeddings-based model, or Neural Collaborative filtering models, and these systems would come in one of these variants - Short vs Long term recommendations, cold start &amp; cohort-based, Multi view and multi-interest models or multi-task recommendations. The most common trend in all these systems usually would be that they all are focused on delivering single user-centric recommendations. These systems were designed to address concerns around user needs, behavior, interests, interactions &amp; personalization. Further, they are measured on user engagement-oriented metrics.</p>
<p>But, caring only about a single user type, might not yield the most optimal outcome especially when there are many stakeholders involved within a platform - aka recommendation systems within a marketplace-type setting could not be designed with a single entity in mind. This is where the need for a recommendation system that caters to different stakeholders with different sets of interests arises.</p>
<p>Hence, Recommendations in marketplaces are multi-sided. Equipped to cater not just to a single user‚Äôs (aka buyer) needs, but also the supplier‚Äôs needs &amp; most often they also have to consider platform economics within the play. Such a system is usually designed with many objectives in mind - some of these objectives are User expectations, user understanding, supplier exposure, supplier goals, platform objectives, and long-term value.</p>
<p>Now let‚Äôs further look into these different stakeholders, their objectives &amp; the interplay between these objectives that usually arise within this ecosystem.</p>
<section id="stakeholders-objectives-the-objective-interplay" class="level2">
<h2 class="anchored" data-anchor-id="stakeholders-objectives-the-objective-interplay">Stakeholders, Objectives &amp; the Objective interplay</h2>
<p>In a multi-sided system with multiple objectives often the objectives interact and behave in different manners. At a high level, you could categorize the different types of these interplay as follows:</p>
<ul>
<li><strong>Correlated</strong> : Optimising for one objective helps the other.</li>
<li><strong>Neutral</strong>: Optimising for one does not impact the other</li>
<li><strong>Anti Correlated</strong>: Optimising for one hurts the other</li>
</ul>
<p>Consider the example of our Hypothetical on-demand delivery startup Hyper, which is a three-sided marketplace - i.e it has three sets of stakeholders with different motivations &amp; objectives.</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 36%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Stakeholder</th>
<th>Needs/Motivations</th>
<th>Potential Objectives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>End User</td>
<td>Wants to order something from local partner shops.</td>
<td><ul>
<li>Quick delivery</li>
<li>Best price</li>
<li>Reliable merchants</li>
<li>Fresh items</li>
</ul></td>
</tr>
<tr class="even">
<td>Merchants</td>
<td>Provide online visibility and find customers.</td>
<td><ul>
<li>Matching quality</li>
<li>Exposure</li>
<li>Minimise wastage</li>
</ul></td>
</tr>
<tr class="odd">
<td>Delivery Partners</td>
<td>Earn a stable livelihood.</td>
<td><ul>
<li>Regularity in jobs</li>
<li>Earnings per partner</li>
<li>Efficient drop location planning</li>
</ul></td>
</tr>
</tbody>
</table>
<p>As we see above each entity has a unique set of potential objectives one could optimise the recommendation system for &amp; this has to be done in a deliberate and careful way or it might result in undesired outcomes.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
üßµ Superstar economics and towards a fair marketplace
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Researchers from Microsoft &amp; Spotify found out that:</p>
<blockquote class="blockquote">
<p>Recommendation systems in general suffer from what is called as an inherent problem of ‚Äúsuperstar economics‚Äù: rankings have a top and a tail end, not just for popularity, but also for relevance. In an attempt to maximize user satisfaction, recommender system optimize for relevance. This inadvertently leads to lock-in of popular and relevant suppliers, especially for users who want to minimize the effort required to interact with the system. A major side-effect of the superstar economics is the impedance to suppliers on the tail-end of the spectrum, who struggle to attract consumers, given the low exposure, and thus, are not satisfied with the marketplace. Indeed, to continue to attract more suppliers to the platform, marketplaces face an interesting problem of optimizing their models for supplier exposure, and visibility. Indeed, the suppliers (e.g.&nbsp;retailers, artists) would want a fair opportunity to be presented to the users.</p>
</blockquote>
<p>Read more about this in <a href="https://dl.acm.org/doi/10.1145/3269206.3272027">Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness &amp; Satisfaction in Recommendation Systems</a></p>
</div>
</div>
</div>
<p>In short, what a system optimizes for is super important &amp; in general, it needs to look for a balance while optimizing for various objectives.</p>
<p>Before we proceed further on how to optimize for multiple objectives let us quickly revisit and see how most modern recommendation systems are built. Also, let‚Äôs do a quick recap of how one builds a ranking model (aka Learning to rank) &amp; some important metrics used for measuring these systems.</p>
</section>
</section>
<section id="a-quick-recap-on-modern-recsys" class="level1">
<h1>A Quick Recap on modern recsys</h1>
<p><img src="assets/recsys-wn.png" class="img-fluid"></p>
<p>Over the past few years, a common and central design pattern has emerged around how most industrial recommendation systems are designed. If one were to summarise this design pattern, it would appear as described in the above figure - consisting of 4 stages. Let us take a brief look at the functionality of these four stages:</p>
<section id="candidate-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="candidate-retrieval">Candidate retrieval</h2>
<p>The Retrieval &amp; filtering stages usually are collectively referred to as candidate generation. A fast but coarse step which narrows down the search space of items from millions of candidates for a given query to something in the order of 100s.</p>
<p>Often this is achieved by an initial retrieval with some form of matching between the query and the catalog.Usually, via an ANN, Graph-based approach, or some form of a decision tree. Followed by a filtering stage, where invalid candidates are removed from the initial retrieval before passing on to the next stages.</p>
</section>
<section id="ranking" class="level2">
<h2 class="anchored" data-anchor-id="ranking">Ranking</h2>
<p>At this phase, we further narrow the initial set of items into a much smaller list to be presented to the user. Which is a slow but more precise operation - this stage is usually modeled as an LTR or a classification task. Further, sometimes it‚Äôs followed by an ordering stage which handles various business logic to reorder/sort the final list of items. Some common examples of this business logic include: organizing recommendations to fit genre distributions in streaming services or promoting specific segments of sellers as in the case of e-commerce.</p>
<div class="callout-tip callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
üìù Suggested reading
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most Production recommendation systems are indeed complex in nature, but the above pattern which was conceptulised at Nvidea by <a href="https://twitter.com/Even_Oldridge"><span class="citation" data-cites="Even_Oldridge">@Even_Oldridge</span></a> &amp; <a href="https://twitter.com/karlhigley"><span class="citation" data-cites="karlhigley">@karlhigley</span></a> sort of provides a good overview of how these systems are designed &amp; to read a bit more on this, refer to <a href="https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e">Recommender Systems not just recommender models</a> article &amp; also read <a href="https://eugeneyan.com/writing/system-design-for-discovery/">system-design-for-discovery</a> from <a href="https://twitter.com/eugeneyan"><span class="citation" data-cites="eugeneyan">@eugeneyan</span></a> where he summarises this design pattern in depth and points to multiple examples from industry that follow this pattern.</p>
</div>
</div>
</section>
</section>
<section id="a-quick-recap-on-learning-to-rank" class="level1">
<h1>A Quick Recap on Learning to Rank</h1>
<p>Learning to rank (LTR) refers to a class of ML techniques for training a model to solve the task of ranking a set of items. Usually, this is formulated as a supervised or sometimes semi-supervised task.</p>
<p>Generally, this means we try to learn a function <span class="math inline">\(f(q, D)\)</span> given a query <span class="math inline">\(q\)</span> &amp; a list of documents <span class="math inline">\(D\)</span> to predict the order/rank of the documents within this list. Depending on how the loss function is formulated in the underlying task, any LTR algorithm can be classified into 3 distinct categories:</p>
<ol type="1">
<li>Pointwise method</li>
<li>Pairwise method</li>
<li>Listwise method</li>
</ol>
<section id="ranking-task" class="level2">
<h2 class="anchored" data-anchor-id="ranking-task">Ranking Task</h2>
<p>Given a query <span class="math inline">\(q\)</span>, and a set of <span class="math inline">\(n\)</span> documents <span class="math inline">\(D=d_1,d_2,...,dn\)</span>, we‚Äôd like to learn a function <span class="math inline">\(f\)</span> such that <span class="math inline">\(f(q, D)\)</span> will predict the relevance of any given document associated with a query.</p>
</section>
<section id="pointwise-method" class="level2">
<h2 class="anchored" data-anchor-id="pointwise-method">Pointwise method</h2>
<p>In pointwise method, the above ranking task is re-formulated as a standard classification/regression task. The function to be learned <span class="math inline">\(f(q, D)\)</span> is simplified as <span class="math inline">\(f(q, d_i)\)</span> i.e the relevance of each document given a query is scored independently.</p>
<p>For instance, if we have two queries associated with 2 and 3 resulting matched documents:</p>
<ol type="1">
<li><span class="math inline">\(q_1 \to d_1, d_2\)</span></li>
<li><span class="math inline">\(q_2 \to d_3, d_4, d_5\)</span></li>
</ol>
<p>Then the training data <span class="math inline">\(x_i\)</span> in a pointwise method will essentially be every query-document pair as follows:</p>
<ol type="1">
<li><span class="math inline">\(x_1 : q_1, d_1\)</span></li>
<li><span class="math inline">\(x_2 : q_1, d_2\)</span></li>
<li><span class="math inline">\(x_3 : q_2, d_3\)</span></li>
<li><span class="math inline">\(x_4 : q_2, d_4\)</span></li>
<li><span class="math inline">\(x_5 : q_2, d_5\)</span></li>
</ol>
<p>Since each document is scored independently with the absolute relevance as the target label, the task is no different from any standard classification or regression task. As such any standard ml algorithms can be leveraged in this setting.</p>
</section>
<section id="pairwise-method" class="level2">
<h2 class="anchored" data-anchor-id="pairwise-method">Pairwise method</h2>
<p>In pairwise method, the goal is to learn a pointwise scoring function <span class="math inline">\(f(q, d_i)\)</span> similar to a pointwise formulation. However, the key difference arises in how the training data is consructed - where we take pairs of documents within the same query as training samples.</p>
<ol type="1">
<li><span class="math inline">\(x_1 \to q_1, (d_1, d_2)\)</span></li>
<li><span class="math inline">\(x_2 \to q_1, (d_3, d_4)\)</span></li>
<li><span class="math inline">\(x_3 \to q_1, (d_3, d_5)\)</span></li>
<li><span class="math inline">\(x_4 \to q_1, (d_4, d_5)\)</span></li>
</ol>
<p>In this setting, a new set of pairwise binary labels are derived, by comapring the individual relevance score in each pair. For example, given the first query <span class="math inline">\(q_1\)</span>, if <span class="math inline">\(y_1==\)</span> (i.e.. an irrelevant document) for <span class="math inline">\(d_1\)</span> &amp; <span class="math inline">\(y_2=3\)</span> (i.e.. a Highly relevant document) for <span class="math inline">\(d_2\)</span> then we can create a new label <span class="math inline">\(y_1&lt;y_2\)</span> for the pair of docs <span class="math inline">\((d_1, d_2)\)</span> - by doing so we have essentially converted this back to a binary classification task again.</p>
<p>Now in order to learn the function <span class="math inline">\(f(q, d_i)\)</span> which is still pointwise, but in a pairwise manner, we model the difference in scores probablistically as follows:</p>
<p><span class="math display">\[P(i&gt;j) \equiv \frac{1}{1+exp^{-(s_i - s_j)}}\]</span></p>
<p>i.e, if document <span class="math inline">\(i\)</span> is better matched than document <span class="math inline">\(j\)</span> (denoted as <span class="math inline">\(i&gt;j\)</span>), then the probability of the scoring function to have scored <span class="math inline">\(f(q, d_i) = S_i\)</span> should be close to 1. In other words, the model is trying to learn, given a query, how to score a pair of documents such that a more relevant document would be scored higher.</p>
</section>
<section id="listwise-method" class="level2">
<h2 class="anchored" data-anchor-id="listwise-method">Listwise method</h2>
<p>Listwise methods, solve the problem of ranking by learning to score the entire list jointly and they do so via two main sub techniques:</p>
<ul>
<li>Direct optimization of IR measures such as NDCG.(Eg: SoftRank, AdaRank).</li>
<li>Minimize a loss function that is defined based on understanding the unique properties of the kind of ranking you are trying to achieve. (E.g. ListNet, ListMLE).</li>
</ul>
<p>Let‚Äôs do a quick review of one of these approaches:</p>
<p>Consider ListNet, Which is based on the concept of permutation probability of a list of items. In this case we assume there is a pointwise scoring function <span class="math inline">\(f(q,di)\)</span> used to score and rank a given list of items. But instead of modeling the probability as a pairwise comparison using scoring difference, we model the probability of the entire list of results. In this setting our documents and query dataset would appear like this:</p>
<ol type="1">
<li><span class="math inline">\(x_1 : q_1, (d_1, d_2)\)</span></li>
<li><span class="math inline">\(x_2 : q_2, (d_3, d_4, d_5)\)</span></li>
</ol>
<p>First let‚Äôs look at the Permutation probability. Let‚Äôs denote <span class="math inline">\(œÄ\)</span> as a specific permutation of a given list of length <span class="math inline">\(n\)</span>, <span class="math inline">\(\Theta (s_i) = f(q, d_i)\)</span> as any increasing function of scoring <span class="math inline">\(s_i\)</span> given a query <span class="math inline">\(q\)</span> and a document <span class="math inline">\(i\)</span>. The probability of having a permutation <span class="math inline">\(œÄ\)</span> can be written as follows:</p>
<p><span class="math display">\[P(\pi) = \prod_{i=1}^n \frac{\phi(s_i)}{\sum_{k=i}^n\phi(s_k)}\]</span></p>
<p>To illustrate consider a list of 3 items, then the probability of returning the permutation <span class="math inline">\(s_1\)</span>,<span class="math inline">\(s_2\)</span>,<span class="math inline">\(s_3\)</span> is calculated as follows:</p>
<p><span class="math display">\[P(\pi = \{s_1, s_2, s_3\}) = \frac{\phi(s_1)}{\phi(s_1) + \phi(s_2) + \phi(s_3)} \cdot \frac{\phi(s_2)}{\phi(s_2) + \phi(s_3)} \cdot \frac{\phi(s_3)}{\phi(s_3)}\]</span></p>
<p>Due to computational complexity, ListNet simplies the problem by looking at only the top-one probability of a given item. The top-one probability of object i equals the sum of the permutation probabilities of permutations in which object i is ranked on the top. Indeed, the top-one probability of object i can be written as:</p>
<p><span class="math display">\[P(i) = \frac{\phi(s_i)}{\sum_{k=1}^n \phi(s_k)}\]</span></p>
<p>Given any two list of items represented by top-one probabilities, we can now measure the difference between them using cross entropy. Then we can use an ml algorithm which minimises that cross entropy. The choice of function <span class="math inline">\(œï(‚ãÖ)\)</span>, can be as simple as just an exponential function. When <span class="math inline">\(œï(‚ãÖ)\)</span> is expotential and the list length is two, the solution basically reduces to a pairwise method as described earlier.</p>
<p>With that brief introduction out of the way, let‚Äôs also quickly look at the advantages and disadvantages of each of these approaches:</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 47%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pointwise</td>
<td><ul>
<li>Simplicity, Any standard ML models can be applied without any changes.</li>
</ul></td>
<td><ul>
<li>The results can be often sub-optimal due to not utilizing the full information of the entire list of matching documents for each query.</li>
<li>This requires explicit labels while constructing the dataset, and can be quite expensive.</li>
</ul></td>
</tr>
<tr class="even">
<td>Pairwise</td>
<td><ul>
<li>We don‚Äôt need explicit labels, Only pairwise preferences are required.</li>
<li>The model learns how to rank directly, even though its a pairwise setting, but in theory it can approximate the performance of a general ranking task.</li>
</ul></td>
<td><ul>
<li>The Core Scoring mechanism is still pointwise. Hence, that relative information in the feature space among different documents given the same query is still not fully leveraged.</li>
</ul></td>
</tr>
<tr class="odd">
<td>Listwise</td>
<td><ul>
<li>Theoretically this is a good solution for a ranking task.</li>
</ul></td>
<td><ul>
<li>Costly to compute in its theoretical form and hence several approximations are used in practice.</li>
<li>Scoring function is still pointwise, which could be sub-optimal.</li>
</ul></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="a-quick-recap-on-ranking-evaluation-metrics" class="level1">
<h1>A Quick Recap on Ranking Evaluation metrics</h1>
<p>Over the years, Several metrics have been proposed and widely used for evaluating a ranking model. If we were to summarise them and list the most popular metrics it boils down to this:</p>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Metric Type</th>
<th>Metric</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binary Relevance</td>
<td>Mean Average Precision (MAP)</td>
</tr>
<tr class="even">
<td>Binary Relevance</td>
<td>Mean Reciprocal Rank (MRR)</td>
</tr>
<tr class="odd">
<td>Graded Relevance</td>
<td>Normalized Discounted Cumulative Gain (NDCG)</td>
</tr>
<tr class="even">
<td>Graded Relevance</td>
<td>Expected Reciprocal Rank (ERR)</td>
</tr>
</tbody>
</table>
<p>In general, binary metrics only consider relevant &amp; irrelevant items, while graded metrics consider the ranking among relevant items. The degree of relevancy matters in this case when scoring a list of items.</p>
<section id="mean-average-precision-map" class="level2">
<h2 class="anchored" data-anchor-id="mean-average-precision-map">Mean Average Precision (MAP)</h2>
<p>MAP is a measure based on binary label of relevancy. To compute this first we define precision at k for a given query <span class="math inline">\(P@k(q)\)</span> as:</p>
<p><span class="math display">\[P@k(q) \equiv \frac{\sum_{i=1}^k r_i}{k}\]</span></p>
<p>for an ordered list of prediction <span class="math inline">\(r_i\)</span> for all <span class="math inline">\(k\)</span> items. <span class="math inline">\(ri=1\)</span> if it is relevant and 0 otherwise.Then we define the average precision given a query <span class="math inline">\(AP(q)\)</span> at <span class="math inline">\(k\)</span> items as:</p>
<p><span class="math display">\[AP(q)@k \equiv \frac{1}{\sum_{i=1}^k r_i} \sum_{i=1}^k P@i(q) \times r_i\]</span></p>
<p>Mean Average Precision is just the mean of <span class="math inline">\(AP(q)\)</span> for all queries:</p>
<p><span class="math display">\[MAP \equiv \frac{\sum_{q=1}^Q AP(q)}{Q}\]</span></p>
<p>Also, MAP is an order sensitive metric because of the term <span class="math inline">\(r_i\)</span> in the calculation of AP. It is essentially taking the average of precision at each ranking position and penalizing the precision at positions with irrelevant item by strcitly setting them to zeroes.</p>
<p>Here is a simple example for computing MAP:</p>
<p><img src="assets/map.jpeg" class="img-fluid"></p>
</section>
<section id="mean-reciprocal-rank-mrr-expected-reciprocal-rank-err" class="level2">
<h2 class="anchored" data-anchor-id="mean-reciprocal-rank-mrr-expected-reciprocal-rank-err">Mean Reciprocal Rank (MRR) &amp; Expected Reciprocal Rank (ERR)</h2>
<p>Reciprocal rank metrics focus mainly on the first correctly predicted relevant item in a list. Given a list of items, and say <span class="math inline">\(r_i\)</span> is the rank of the highest ranking relevant item &amp; if the the 2nd item is the first relevant item in the list, then the reciprocal rank for this query would be <span class="math inline">\(\frac{1}{2}\)</span>. By extension, each query will have a reciprocal rank. Hence, Mean reciprocal rank is essentially the average of reciprocal rank for all the queries, which would be represented as follows:</p>
<p><span class="math display">\[MRR \equiv \frac{1}{Q} \sum_{i=1}^Q\frac{1}{r_i}\]</span></p>
<p>Expected reciprocal rank tries to quantify how useful a document at rank <span class="math inline">\(i\)</span> conditioned on the degree of relevance of documents at rank less than <span class="math inline">\(i\)</span> are. The intution behind this is based on the empirical findings from web search task, that the likelihood a user will examine the document at rank <span class="math inline">\(i\)</span> is dependent on how satisfied the user was with previously observed documents in the list.</p>
<p>Lets assume the probability of a user finding the result is satisfied at position <span class="math inline">\(i\)</span> in a list of items is denoted as <span class="math inline">\(R_i\)</span> &amp; the likelihood of a session for which the user is satisfied and stops at position <span class="math inline">\(r\)</span> is: <span class="math display">\[\prod_{i=1}^{r-1}(1 - R_i)R_r\]</span></p>
<p>Now we can model <span class="math inline">\(R_i\)</span> such that it is an increasing function of relevance:</p>
<p><span class="math display">\[R = R(g) \equiv \frac{2^g - 1}{2^{g_{max}}}\]</span></p>
<p>where <span class="math inline">\(g\)</span> is the graded relevance such that <span class="math inline">\(g \in \{0, 1, ..., g_{max}\}\)</span> &amp; <span class="math inline">\(g = 0\)</span> implies an irrelevant document and <span class="math inline">\(g = g_{max}\)</span> implies a relevant document.</p>
<p>Now we can define ERR as follows:</p>
<p><span class="math display">\[ERR \equiv \sum_{r=1}^n\frac{1}{r}R_r\prod_{i=1}^{r-1}(1-R_i)\]</span></p>
<p>Here <span class="math inline">\(\frac{1}{r}\)</span> is treated as a utility function <span class="math inline">\(\tau(r)\)</span> that satisfies <span class="math inline">\(\tau(1) = 1\)</span> and <span class="math inline">\(\tau(r) \rightarrow 0\)</span> as <span class="math inline">\(r \rightarrow \infty\)</span>.</p>
<p>Note that ERR is a metric on a list with a single query, To evaluate results from multiple queries, we will need to further average ERRs among queries.</p>
<p>Here is a simple example for computing MRR:</p>
<p><img src="assets/mrr.jpeg" class="img-fluid"></p>
</section>
<section id="normalized-discounted-cumulative-gain-ndcg" class="level2">
<h2 class="anchored" data-anchor-id="normalized-discounted-cumulative-gain-ndcg">Normalized Discounted Cumulative Gain (NDCG)</h2>
<p>Normalized Discounted Cumulative Gain (NDCG) is one of the most popular metric for measuring the quality of a set of ranked items in search or recommendations. If we were to break the assumptions made by this metric in simple terms, it would be as follows:</p>
<ol type="1">
<li>Cumulative Gain: Very relevant items are more useful than somewhat relevant items which are more useful than completely irrelevant items.</li>
<li>Discounting: Relevant items are more useful when they appear earlier in a list of ranked items.</li>
<li>Normalization: The ranking results should be irrelevant to the query performed.</li>
</ol>
<p>Let‚Äôs define Discounted Cumulative Gain at position <span class="math inline">\(k\)</span> as follows:</p>
<p><span class="math display">\[DCG@k \equiv \sum_{i=1}^k\frac{2^{l_i} - 1}{log_2(i + 1)}\]</span></p>
<p>where <span class="math inline">\(l_i\)</span> is the grading of relevance at rank <span class="math inline">\(i\)</span>. Intutively, the numerator is simply an increasing function of relevance, the more relevant the higher. This is the <em>gain</em> from each item. The denominator is a decreasing function of ranking position, this is the <em>discounted</em> component of the metric. Collectively, higher relevance gains more score, but the lower it is ranked the higher also the discount. Essentially, the metric will prefer higher relevant item to be ranked higher, which is the desired outcome.</p>
<p>NDCG is then defined as:</p>
<p><span class="math display">\[NDCG@k = \frac{DCG@k}{IDCG@k}\]</span></p>
<p>where <span class="math inline">\(IDCG@k\)</span> is the <em>Ideal</em> DCG@k given the result. DCG@k is calculated by sorting the given list of items by its true relevance labels. and IDCG@k is the maximum possible DCG@K value one can get given a ranked list of items.</p>
<p>Here is a simple example for computing NDCG:</p>
<p><img src="assets/ndcg.jpeg" class="img-fluid"></p>
</section>
</section>
<section id="learning-to-rank-with-multiple-objectives" class="level1">
<h1>Learning to rank with Multiple Objectives</h1>
<section id="moo---the-what-the-why-the-how." class="level2">
<h2 class="anchored" data-anchor-id="moo---the-what-the-why-the-how.">MOO - The What, The Why &amp; The How.</h2>
<p>After that long detour, let‚Äôs now look into Multiple Objective Optimisation applied to Ranking problem within a marketplace setting involving multiple stakeholders. Let‚Äôs do so with a simple illustrative example that involves similar item recommendations. Specifically, let‚Äôs understand Why this is needed first.</p>
<p>Picture this, A User has browsed and explored a bunch of different red shirts they are planning to buy, and on one such open tab we‚Äôve got a shirt that they are closely examining. Now, the recommendation system in the backend is also generating a bunch of similar shirts that they might be interested to explore. Let‚Äôs say the recommendation system is optimising for two different objectives - firstly, to show relevant and personalised shirts similar to their style based on interaction history. Secondly, the platform also wants to make sure it‚Äôs making a good profit on each sales that the recommendation system generates or leads to. Hence, they would also want to promote shirts with good porfit margin. How would we do this?</p>
<p>Let‚Äôs start by defining our objectives:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Objective I</th>
<th>Objective II</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Personalisation</td>
<td>Price Margin</td>
</tr>
</tbody>
</table>
<p>Let‚Äôs also say the item options available to us to be displayed (let‚Äôs focus on finding the top-1 item at the moment.) if plotted on a graph look something like this:</p>
<p><img src="assets/items.png" class="img-fluid"></p>
<p>Now, essentially we want to maximise profit margin but also we want to maximise for highly personalised &amp; relevant shirt. If we were to solve this from a lens of single objectve optimisation two scenarios would arise:</p>
<ol type="1">
<li><p>Case-I: Applying 1D Optimisation to objective I followed by optimising for objective II, i.e First we can find Highly Personalised shirts and then search for the shirt that also provides maximum margin.</p></li>
<li><p>Case-II: Applying 1D Optimisation to objective II followed by optimising for objective I, i.e First we can find High Profit margin shirts and then search for the ones which are also Highly Personalised &amp; relevant for the user‚Äôs style.</p></li>
</ol>
<p>For a simple and better understanding of the concept, assume that someone is trying to find the best red shirt from both the perspectives manually in a physical store, and let‚Äôs further also assume its a dark room.</p>
<section id="case-i-highly-personalised-high-profit-margin" class="level3">
<h3 class="anchored" data-anchor-id="case-i-highly-personalised-high-profit-margin">Case I : Highly Personalised &amp; High Profit margin</h3>
<p><img src="assets/relevance-first.png" class="img-fluid"></p>
<ol type="1">
<li>So, in this case the solver turns the torch on towards the relevance axis and discovers <span class="math inline">\(T5\)</span> as the most suitable candidate.</li>
<li>Now from this point the solver turns towards the profit axis and turns the torch on and discovers <span class="math inline">\(T6\)</span>.</li>
</ol>
</section>
<section id="case-ii-high-profit-margin-high-personalisation" class="level3">
<h3 class="anchored" data-anchor-id="case-ii-high-profit-margin-high-personalisation">Case II : High Profit margin &amp; High Personalisation</h3>
<p><img src="assets/profit-first.png" class="img-fluid"></p>
<ol type="1">
<li>In this case the solver turns the torch on towards the profit axis and discovers <span class="math inline">\(T3\)</span> as the best candidate.</li>
<li>Now from this point the solver turns towards the relevance axis and turns the torch on and discovers <span class="math inline">\(T4\)</span>.</li>
</ol>
<p>What do we have as of now:</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 33%">
<col style="width: 32%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Process</th>
<th>1st Optimization Objective</th>
<th>2nd Optimization Objective</th>
<th>Optimal Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Personalisation</td>
<td>Profit Margin</td>
<td><span class="math inline">\(T6\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td>Profit Margin</td>
<td>Personalisation</td>
<td><span class="math inline">\(T4\)</span></td>
</tr>
</tbody>
</table>
<p>So, that seems odd. There are multiple solutions. Depending on what we want to achieve- If we want to optimize for both objectives and find the best solution, Going about in the above method is not the best way. Instead, we need to optimize to find solutions for both objectives collectively. The set of optimization methods that enables this is called <em>Multiple Objective Optimization</em>.</p>
<p>Let‚Äôs define what MOO is &amp; try to understand some other key concepts associated with it.</p>
<div class="callout-caution callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Basic Concepts - Defining the MOO Problem, Pareto Optimum &amp; Pareto Frontier
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>MOO</strong>: Optimization that involves identifying the values of decision (or free) variables that generate the maximum or minimum of one or more objectives. In most engineering problems, there may exist multiple, conflicting objectives and solving the optimization problems is not trivial or may not be even feasible sometimes. One way to formulate this is as follows:</p>
<p>Given <span class="math inline">\(m\)</span> inequality constraints &amp; <span class="math inline">\(p\)</span> equality constraints identify a vector <span class="math inline">\(\bar{x}^*_n = [x^*_1, x^*_2,...,x^*_n]^T\)</span> that optimizes</p>
<p><span class="math display">\[\bar{f}_k(\bar{x}_n) = [o_1(\bar{x}_n), o_2(\bar{x}_n),..., o_k(\bar{x}_n)]^T\]</span></p>
<p>such that</p>
<p><span class="math display">\[g_i(\bar{x}_n) ‚â• 0, i = 1, 2, . . . , m\]</span></p>
<p><span class="math display">\[h_i( \bar{x}_n) = 0, i = 1, 2, . . . , p\]</span></p>
<p>where <span class="math inline">\(\bar{x}_n = [x_1, x_2, . . . , x_n]^T\)</span> is a vector of <span class="math inline">\(n\)</span> decision variables. The constraints determine the ‚Äúfeasible region‚Äù <span class="math inline">\(F\)</span> and any point <span class="math inline">\(\bar{x}_n ‚àà F\)</span> gives a ‚Äúfeasible solution‚Äù where <span class="math inline">\(g_i( \bar{x}_n)\)</span> and <span class="math inline">\(h_i( \bar{x}_n)\)</span> are the constraints imposed on decision variables. The vector function <span class="math inline">\(\bar{f}_k(\bar{x}_n)\)</span> above is a set of <span class="math inline">\(k\)</span> objective functions, <span class="math inline">\(o_i(\bar{x}_n)\)</span> for <span class="math inline">\(i = 1, ¬∑ ¬∑ ¬∑ , k\)</span>, representing k non-commensurable criteria.</p>
<p><strong>Pareto Optimum</strong>: A point <span class="math inline">\(\bar{x}^‚àó\)</span> is ‚ÄúPareto optimal‚Äù (for minimisation task) if the following holds for every <span class="math inline">\(\bar{x}_n ‚àà F\)</span></p>
<p><span class="math display">\[\bar{f}_k(\bar{x}^*_n) ‚â§  \bar{f}_k( \bar{x}_n)\]</span></p>
<p>where <span class="math inline">\(\bar{f}_k(\bar{x}_n) = [o_1(\bar{x}_n), o_2(\bar{x}_n),..., o_k(\bar{x}_n)]^T\)</span>, <span class="math inline">\(\bar{f}^*_k(\bar{x}^*_n) = [o_1(\bar{x}^*_n), o_2(\bar{x}^*_n),..., o_k(\bar{x}^*_n)]^T\)</span></p>
<p>Pareto optimality gives a set of nondominated solutions. A feasible solution <span class="math inline">\(x\)</span> is called ‚Äúweakly nondominated‚Äù if there is no <span class="math inline">\(y ‚àà F\)</span> , such that <span class="math inline">\(o_i(y) &lt; o_i(x)\)</span> for all <span class="math inline">\(i = 1, 2, ..., k\)</span>. This means that there is no other feasible solution that can strictly dominate <span class="math inline">\(x\)</span>. A feasible solution <span class="math inline">\(x\)</span> is called ‚Äústrongly nondominated‚Äù if there is no <span class="math inline">\(y ‚àà F\)</span> , such that <span class="math inline">\(o_i(y) ‚â§ o_i(x)\)</span> for all <span class="math inline">\(i = 1, 2, ...k\)</span>, and <span class="math inline">\(o_i(y) &lt; o_i(x)\)</span> for at least one <span class="math inline">\(i\)</span>. This means that there is no other feasible solution that can improve some objectives without worsening at least one other objective. If <span class="math inline">\(x\)</span> is ‚Äústrongly nondominated‚Äù, it is also ‚Äúweakly nondominated‚Äù.</p>
<p><strong>Pareto Frontier</strong>: A set (of feasible solutions) that is Pareto efficient is called the Pareto frontier, Pareto set, or Pareto front. The optimal solutions can be determined based on the tradeoffs within this set based on a designer‚Äôs decisions for acceptable performance.</p>
<p>read more on this from <a href="https://people.cs.vt.edu/~irchen/ps/Cho-ieeecst17.pdf">A Survey on Modeling and Optimizing Multi-Objective Systems</a></p>
</div>
</div>
</div>
</section>
</section>
<section id="popular-methods-applied-to-ltr-setting." class="level2">
<h2 class="anchored" data-anchor-id="popular-methods-applied-to-ltr-setting.">Popular methods applied to LTR Setting.</h2>
<p>Over the years, numerous approaches have been applied in LTR settings. Broadly most of these approaches can be classified into four categories as follows:</p>
<ol type="1">
<li>Label Aggregation</li>
<li>Constraint Optimization</li>
<li>Model Fusion/Aggregation</li>
<li>Lexicographic</li>
</ol>
<p>Now, lets us define these approaches.</p>
</section>
<section id="label-aggregation" class="level2">
<h2 class="anchored" data-anchor-id="label-aggregation">Label Aggregation</h2>
<p>In this method, we combine all objective functions to form a single objective function which is then minimized. Once we convert the multi-objective into a single objective by combing the labels, we solved the given LTR problem as the single objective function. Let‚Äôs say for given query q, and products P, we have two different labels, <span class="math inline">\(‚Ñì_1(q,p)\)</span> a similarity score between query and prodct, and <span class="math inline">\(‚Ñì_2(p)\)</span> a profit margin for a product, we can put a new label as <span class="math inline">\(‚Ñì(q, p) = \alpha¬∑‚Ñì_1(q, p) + (1 ‚àí \alpha)¬∑‚Ñì2(p)\)</span></p>
<p>Note: Here <span class="math inline">\(\alpha\)</span> is manually chosen by the user. If <span class="math inline">\(\alpha \in \{0,1\}\)</span>, the problem is reduced to a single objective optimization.</p>
<p>In general, given k objectives rank function looks like below:</p>
<p>Minimise,</p>
<p><span class="math display">\[f(x) = \sum_{i=1}^k{\alpha_i * f_i(x)}\]</span></p>
<p>Subject to <span class="math display">\[\sum_{i=1}^k{\alpha_i = 1}\]</span></p>
<section id="advantages" class="level4">
<h4 class="anchored" data-anchor-id="advantages">Advantages</h4>
<ol type="1">
<li>It gives a clear interpretation of the multi-objective function and generalize it.</li>
<li>It allows multiple parameters to be set to reflect preferences.</li>
</ol>
</section>
<section id="disadvantages" class="level4">
<h4 class="anchored" data-anchor-id="disadvantages">Disadvantages</h4>
<ol type="1">
<li>It tries to optimize for each objective function, which can be computationally expensive.</li>
<li>The setting of parameters <span class="math inline">\((\alpha_i)\)</span> is not intuitively clear when only one solution point is desired.</li>
</ol>
</section>
</section>
<section id="constraint-optimization" class="level2">
<h2 class="anchored" data-anchor-id="constraint-optimization">Constraint Optimization</h2>
<p>This method optimizes the single most important objective <span class="math inline">\(f_{primary}(x)\)</span> and treat the other objectives as constraints with pre-determined upperbound. As we saw eariler, let‚Äôs say have two objectives to optimize. First objective is <span class="math inline">\(‚Ñì_1(q,p)\)</span> - similarity score between <span class="math inline">\((p,q)\)</span> and second <span class="math inline">\(‚Ñì_2(p)\)</span> - profit margin for <span class="math inline">\(o\)</span>. Then we could consider <span class="math inline">\(‚Ñì_1(q,p)\)</span> as primary objective and <span class="math inline">\(‚Ñì_2(p)\)</span> as secondary objective. In this method we will optimize for primary objective <span class="math inline">\(‚Ñì_1(q,p)\)</span> subject to <span class="math inline">\(‚Ñì_2(p) \lesssim \epsilon\)</span>.</p>
<p>In general, given k objectives the ranking function is as follows:</p>
<p><span class="math display">\[ \min_{\forall x_i} f_l(x)\]</span></p>
<p>Subject to <span class="math display">\[ f_i(x) \lesssim \epsilon_i, \forall i \not =  l ,\]</span> <span class="math inline">\(\epsilon_i\)</span> is upperbound for <span class="math inline">\(f_i(x)\)</span>. And, <span class="math inline">\(f_l(x)\)</span> is the primary function to optimize.</p>
<section id="advantages-1" class="level4">
<h4 class="anchored" data-anchor-id="advantages-1">Advantages</h4>
<ol type="1">
<li>It focuses on a single objective with limits on others.</li>
<li>It always provides a weakly Pareto optimal point, assuming that the formulation gives a solution.</li>
<li>It is not necessary to normalize the objective functions.</li>
</ol>
</section>
<section id="disadvantages-1" class="level4">
<h4 class="anchored" data-anchor-id="disadvantages-1">Disadvantages</h4>
<ol type="1">
<li>The optimization problem may be infeasible if the bounds on the objective functions are not appropriate.</li>
</ol>
</section>
</section>
<section id="model-fusionaggregation" class="level2">
<h2 class="anchored" data-anchor-id="model-fusionaggregation">Model Fusion/Aggregation</h2>
<p>This method is an aggregation of multiple independent ranking models. The final ranking socre is obtained by a convex combination of multiple models. As we saw earlier if we have two objectives, let‚Äôs say <span class="math inline">\(‚Ñì_1(q,p)\)</span> - similarity between query and product and <span class="math inline">\(‚Ñì_2(p)\)</span> - profit margin. Then first we train the <span class="math inline">\(M_{l1}\)</span> model which optimizes for similarity score between (q,p). And further we also independently train another model <span class="math inline">\(M_{l2}\)</span> which optimizes for the profit margin. The linear combination of the models can be formulated as <span class="math inline">\(M(q,p) = \alpha¬∑M_{l1}(q, p) + (1 ‚àí Œ±)¬∑M_{l2}(p)\)</span>, where the hyperparameter <span class="math inline">\(\alpha \in[0, .,., 1]\)</span> controls the tradeoff between the two model scores.</p>
<p>In general, given k objectives the ranking function looks as follows:</p>
<p><span class="math display">\[M(x) = \sum_{i=1}^k (\alpha_i * M_i (x))\]</span></p>
<p>where, <span class="math inline">\(M_i(x)\)</span> is an independently trained model for optimizing <span class="math inline">\(i^{th}\)</span> objective.</p>
<section id="advantages-2" class="level4">
<h4 class="anchored" data-anchor-id="advantages-2">Advantages</h4>
<ol start="2" type="1">
<li>This is used as a post-rank method, and as such easy to tweak weighting parameters.</li>
<li>Learning for one single objective will not be affected by other objectives (decoupled objectives).</li>
</ol>
</section>
<section id="disadvantages-2" class="level4">
<h4 class="anchored" data-anchor-id="disadvantages-2">Disadvantages</h4>
<ol type="1">
<li>It‚Äôs difficult to find the optimal weight for the final ranking.</li>
</ol>
</section>
</section>
<section id="lexicographic" class="level2">
<h2 class="anchored" data-anchor-id="lexicographic">Lexicographic</h2>
<p>When we have more than one objective, we rank the items by ordering the objective functions according to their importance. As mentioned earlier, we have two objective functions, <span class="math inline">\(‚Ñì_1(q,p)\)</span> similarity between query and product as pprimary objective and <span class="math inline">\(‚Ñì_2(p)\)</span> profit margin as the secondary objective. Then We will order the items according to the primary objective <span class="math inline">\(‚Ñì_1(q,p)\)</span> and if a tie happens, then we use <span class="math inline">\(‚Ñì_2(p)\)</span> the secondary objective score to break the tie.</p>
<p>In general, given k objectives, the rank function looks like below:</p>
<p>Minimise,</p>
<p><span class="math display">\[ f_i(x)\]</span></p>
<p>Subject to <span class="math display">\[ f_j(x) \lesssim f_j(x_j^*)\]</span> <span class="math inline">\(j = 1\)</span> to (<span class="math inline">\(i - 1\)</span>) and <span class="math inline">\(i &gt; 1\)</span> ; <span class="math inline">\(i = 1\)</span> to <span class="math inline">\(k\)</span></p>
<p>Here, we rank the function based on <span class="math inline">\(f_i\)</span>, and where a tie occurs we break the tie based on <span class="math inline">\(f_{(i+1)}\)</span> score.</p>
<section id="advantages-3" class="level4">
<h4 class="anchored" data-anchor-id="advantages-3">Advantages</h4>
<ol type="1">
<li>It is a unique approach to specifying preferences.</li>
<li>It does not require that the objective functions be normalized.</li>
</ol>
</section>
<section id="disadvantages-3" class="level4">
<h4 class="anchored" data-anchor-id="disadvantages-3">Disadvantages</h4>
<ol type="1">
<li>It requires that additional constraints be imposed.</li>
<li>It is computation heavy if we have more objectives.</li>
</ol>
</section>
</section>
<section id="few-examples-in-the-wild" class="level2">
<h2 class="anchored" data-anchor-id="few-examples-in-the-wild">Few Examples in the Wild</h2>
<section id="a-multi-objective-learning-to-re-rank-approach-to-optimize-online-marketplaces-for-multiple-stakeholders." class="level3">
<h3 class="anchored" data-anchor-id="a-multi-objective-learning-to-re-rank-approach-to-optimize-online-marketplaces-for-multiple-stakeholders.">A Multi-Objective Learning to Re-Rank Approach to Optimize Online Marketplaces for Multiple Stakeholders.</h3>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Read the Original Paper over here: <a href="https://arxiv.org/pdf/1708.00651.pdf">Original Paper</a></p>
</div>
</div>
</div>
<p>First, let‚Äôs look at an example from Expedia. Being a service provider they are trying to optimize for the following objectives:</p>
<ol type="1">
<li>Consumer‚Äôs Conversion Rate or Click Through Rate.</li>
<li>Maximum transaction commission from the supplier.</li>
</ol>
<p>A supplier pays a marginal amount of the sales transaction as a commission to the platform. Let‚Äôs say the product‚Äôs cost is <span class="math inline">\(c\)</span> and the selling price is <span class="math inline">\(p\)</span> then the margin is <span class="math inline">\(m = p-c\)</span>.</p>
<p>To achieve the above objectives, the optimization function is defined as follows:</p>
<p><span class="math display">\[\max_{\alpha, \beta}L(m|u) = \sum_{i=1}^n \log(u_i) + \alpha \log(p_i) + \beta \log(\frac{m_i}{p_i})\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are tuning parameters.</p>
<p><span class="math inline">\(\log(u_i)\)</span> = User possibility to do transaction.</p>
<p><span class="math inline">\(\log(p_i)\)</span> = supplier interest for selling the product at price <span class="math inline">\(p\)</span>.</p>
<p><span class="math inline">\(\log(m/p)\)</span> = profit margin define as percentage here.</p>
<p>In these objective functions, we have contradictory relations with suppliers and consumers by nature. On the other side, service providers want higher commission benefits from suppliers at an indirect cost to consumers. For such problems, there is no unique Pareto optimal solution because of the complex and opposing interactions of the different stakeholder interests.</p>
<p>Here they give priority to promoting items to higher positions that better satisfy a transaction commission objective while staying as close as possible to the original ranking. The new ranking score function looks like the below:</p>
<p><span class="math display">\[ \forall_u \in u, u^{‚Ä≤} = u + \alpha\log(p) + \beta(x,m)\log(\frac{m}{p})\]</span></p>
<p>To reduce the distance between the new vs old score vectors, they use the <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall tau</a> correlation measure. The updated objective function looks like the below:</p>
<p><span class="math display">\[\min_{\alpha, \beta}L(m|u, X) = L_r(\frac{m}{X}) + \gamma(1 - K^{'}(u, u^{‚Ä≤})) \]</span></p>
<p>Here, <span class="math inline">\(K^{'}(u, u^{'})\)</span> is playing the role of a similarity-based regularizer with the original ranking order u being the reference point to the new ranking order <span class="math inline">\(u^{‚Ä≤}\)</span>. The hyperparameter <span class="math inline">\(\gamma\)</span> gives the balance between our objective function.</p>
<p>To evaluate the LTR method, they use an in-house Expedia dataset built from worldwide hotel searches collected during 2016. The new ranking methods give a lift¬â of +16.7% on the NDCG of margin, but at the same time, this incurs a decrease of -5.9% in terms of the NDCG of customer preferences.</p>
<p>The paper also uses the following formula to calculate the risk and reward to further evaluate the new objective function:</p>
<p><span class="math display">\[ Risk = \frac{1}{|q|} \sum_q NDCG@10(LRR) &lt; NDCG@10(Baseline)\]</span></p>
<p><span class="math display">\[ Reward = \frac{1}{|q|} \sum_q NDCG@10(LRR) &gt; NDCG@10(Baseline)\]</span></p>
<p>They have found that the risk is lower than the baseline and the reward much higher.</p>
<p>This experiment shows that multi-objective is always a trade-off between the two objectives: Conversion rate vs Margin. They would like to further test with real-world performance via <span class="math inline">\(A/B\)</span> testing.</p>
</section>
<section id="joint-optimization-of-profit-and-relevance-for-recommendation-systems-in-e-commerce" class="level3">
<h3 class="anchored" data-anchor-id="joint-optimization-of-profit-and-relevance-for-recommendation-systems-in-e-commerce">Joint Optimization of Profit and Relevance for Recommendation Systems in E-commerce</h3>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Read the Original Paper over here: <a href="http://ceur-ws.org/Vol-2440/short1.pdf">Original Paper</a></p>
</div>
</div>
</div>
<p>Traditionally, e-commerce-based recommendation systems focus on optimizing for relevance by predicting the purchase or click probability of an item. The relevance-centric approach is capable to increased the conversion rate but does not guarantee a maximum profit for either a platform or seller. In this paper from Etsy, where they discussed a novel revenue model, which optimizes for two objectives:</p>
<ol type="1">
<li>Maximising the Revenue</li>
<li>The probability of the purchase.</li>
</ol>
<p>To maximize the likelihood, the objective function is defined as follows:</p>
<p><span class="math display">\[\max_{w \in R^n, b \in R} l(w,b) := - \sum_{i=1}^{m} \log(1 + exp(-y_i(w^T x_i + b)))\]</span></p>
<p>Here, <span class="math inline">\(x_i\)</span> = <span class="math inline">\(i^{th}\)</span> training sample <span class="math inline">\(x_i \in R^n\)</span> <span class="math inline">\(y_i\)</span> = label whether a recommended item is purchased or not</p>
<p>Let‚Äôs say <span class="math inline">\(\pi_i\)</span> is the price of item, then the objective function for maximizing profit is as below:</p>
<p><span class="math display">\[œÅ(w,b) := \sum_{i=1}^{m} E[\pi_i, y_i] = \sum_{i=1}^{m} \pi_i (2prob[y_i = 1|x_i;w] - 1)\]</span></p>
<p><span class="math display">\[= \sum_{i=1}^{m} 2\pi_i\sigma(w^T x_i + b) - \pi_i,\]</span></p>
<p>The combined objective function will be:</p>
<p><span class="math display">\[\max_{w\in R^n, b\in R } l(w,b) + \mu œÅ(w,b)\]</span></p>
<p>To optimise the above objective, <span class="math inline">\((w,b)\)</span> parameters need to be found which can fit <span class="math inline">\(l(w,b)\)</span> to maximise the likelihood while maximizing the expected revenue (via <span class="math inline">\(œÅ(w, b)\)</span>). Here, <span class="math inline">\(\mu ‚â• 0\)</span> is a hyperparameter of the model that controls the tradeoff between the two objectives. Once the optimal parameters are learned, they use them to rank a set of candidate items.</p>
<p>They have used the following metrics to evaluate the performance of the proposed model</p>
<ol type="1">
<li>Profit@K: profit generate by kth highest ranked item</li>
<li>Average price: Average price of the k highest ranked item</li>
<li>AUC: to measure relevance</li>
<li>NDCG@5</li>
</ol>
<p>Etsy has done an offline evaluation of the proposed model. They found the proposed revenue model attains the highest AUC and profit@k for all K values. Note they used K value up to 3. They observe that the revenue model has a 3.57% increase in AUC and 9.50% in profit@1 compared to the baseline model. Also increases P-NDCG@k and AP@k for all k by at least 3.57% and 23.08% However, the proposed model results in a 10.76% and 16.06% decrease in AUC compared to the baseline.</p>
<p>The overall revenue model can increase profit for the platform while retaining high relevancy for users. They would like to assess revenue model performance in the face of real user traffic via an online A/B experiment.</p>
</section>
<section id="using-bayesian-optimization-for-balancing-metrics-in-recommendation-systems" class="level3">
<h3 class="anchored" data-anchor-id="using-bayesian-optimization-for-balancing-metrics-in-recommendation-systems">Using Bayesian optimization for balancing metrics in recommendation systems</h3>
<div class="callout-tip callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Read the Original article over here: <a href="https://engineering.linkedin.com/blog/2022/using-bayesian-optimization-for-balancing-metrics-in-recommendat">Original Article</a></p>
</div>
</div>
</div>
<p>Let‚Äôs now look into an article from Linkedin where they describe their approach towards building their notifications recommendation system, which notifies members about various activities within their network. To build an efficient notification system, they are optimizing for the following objects:</p>
<ol type="1">
<li>CTR</li>
<li>Number of sessions (i.e the user visits &amp; app open rate)</li>
</ol>
<p>The CTR and session objectives can be conflicting, because sending more notifications to members may lead them to visit an app frequently. And It increases the overall number of sessions but on the other side, it can decrease CTR because of the quality of the notification.</p>
<p>The overall objective function they define is as follows:</p>
<p><span class="math display">\[p_{click} + \alpha * \Delta p_{visit} &gt; \gamma\]</span></p>
<p>where,</p>
<ol type="1">
<li><span class="math inline">\(p_{click}\)</span> is the probability of click by member</li>
<li><span class="math inline">\(\Delta p_{visit}\)</span> can be defined as <span class="math inline">\(p(\frac{visit}{sent})\)</span> - <span class="math inline">\(p(\frac{visit}{not sent})\)</span>. Which is basically the difference between sending a notification now vs not sending a notification.</li>
<li><span class="math inline">\(\alpha\)</span> is the hyperparameter that measures the relative importance of the two utilities.</li>
<li><span class="math inline">\(\gamma\)</span> is the threshold applied.</li>
</ol>
<p>Finding an optimal value of <span class="math inline">\(x=\{\alpha,\gamma\}\)</span> can maximize the sessions without compromising on CTR and send volume. To ensure the overall performance, they used <span class="math inline">\(c1\)</span> and <span class="math inline">\(c2\)</span> constraints as contained for CTR(x), and Send Volume(x).</p>
<p>The updated objective function looks like the below:</p>
<p><span class="math display">\[ \max_{\forall x_i} , f_{session}(x)\]</span></p>
<p>Such that, <span class="math display">\[f_{CTR}(x) &gt; c_1, f_{sentVolume} (x) &lt; c_2\]</span></p>
<p>Using the above constraints, they define a single objective function as below:</p>
<p><span class="math display">\[\max_x f(x) = f_{session}(x) + \lambda(1 \{f_{CTR}(x) &gt; c_1 \} + 1\{f_{sentVolume(x)} &lt; c_2\}),\]</span></p>
<p>By converting a MOO into SOO using constrained-based optimization, they learn global hyperparameters (i.e., a single value) for all members. Further, they evaluate and improve upon this via online A/B experiments.</p>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ol type="1">
<li><a href="https://arxiv.org/pdf/2002.05753.pdf">Multi-objective Ranking via Constrained Optimization</a></li>
<li><a href="https://assets.amazon.science/4d/9c/69cbef8346408349385c780cac48/scipub-1195.pdf">Multi-Objective Ranking Optimization for Product Search Using Stochastic Label Aggregation</a></li>
<li><a href="https://arxiv.org/pdf/1707.08029.pdf">Price and Profit Awareness in Recommender Systems</a></li>
<li><a href="https://arxiv.org/pdf/1908.08328.pdf">Measuring the Business Value of Recommender Systems</a></li>
<li><a href="https://bytes.swiggy.com/multi-objective-ranking-using-constrained-optimization-in-gbts-7f814f5ed696">Multi-objective ranking using Constrained Optimization in GBTs</a></li>
<li><a href="https://medium.com/@ebaytechblog/multi-objective-ranking-for-promoted-auction-items-293bf204574f">Multi-Objective Ranking for Promoted Auction Items</a></li>
<li><a href="https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e">Recommender Systems, Not Just Recommender Models</a></li>
<li><a href="https://blog.flipkart.tech/automated-demand-shaping-guaranteeing-view-share-2d1ac198e0b3">Automated Demand Shaping Guaranteeing View Share</a></li>
<li><a href="https://economictimes.indiatimes.com/tech/technology/startups-recalibrate-approach-to-ten-minute-deliveries-amid-operational-challenges/articleshow/92045165.cms?from=mdr">Why nobody is talking about 10-minute deliveries anymore</a></li>
<li><a href="https://people.cs.vt.edu/~irchen/ps/Cho-ieeecst17.pdf">A Survey on Modeling and Optimizing Multi-Objective Systems</a></li>
<li><a href="https://arxiv.org/pdf/1806.11371.pdf">Personalizing Similar Product Recommendations in Fashion E-commerce</a></li>
<li><a href="http://www.wsdm-conference.org/2010/proceedings/docs/p11.pdf">Towards Recency Ranking in Web Search</a></li>
<li><a href="https://dl.acm.org/doi/10.1145/3269206.3272027">Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness &amp; Satisfaction in Recommendation Systems</a></li>
<li><a href="https://arxiv.org/pdf/1708.00651.pdf">A Multi-Objective Learning to re-Rank Approach to Optimize Online Marketplaces for Multiple Stakeholders</a></li>
<li><a href="http://ceur-ws.org/Vol-2440/short1.pdf">Joint Optimization of Profit and Relevance for Recommendation Systems in E-commerce</a></li>
<li><a href="http://ceur-ws.org/Vol-2440/paper1.pdf">A Multistakeholder Recommender Systems Algorithm for Allocating Sponsored Recommendations</a></li>
<li><a href="https://engineering.linkedin.com/blog/2022/using-bayesian-optimization-for-balancing-metrics-in-recommendat">Using Bayesian optimization for balancing metrics in recommendation systems</a></li>
<li><a href="http://ceur-ws.org/Vol-2440/paper5.pdf">Simple Objectives Work Better</a></li>
<li><a href="http://www.xuanhui.me/pub/click-shaping-kdd11.pdf">Click Shaping to Optimize Multiple Objectives</a></li>
<li><a href="http://www.xuanhui.me/pub/wsdm427-kang.pdf">Learning to Rank with Multi-Aspect Relevance for Vertical Search</a></li>
<li><a href="https://arxiv.org/pdf/2008.10277.pdf">Sample-Rank: Weak Multi-Objective Recommendations Using Rejection Sampling</a></li>
<li><a href="https://daiwk.github.io/assets/youtube-multitask.pdf">Recommending What Video to Watch Next: A Multitask Ranking System</a></li>
<li><a href="https://www.youtube.com/watch?v=nCtM4Xg7e4k">How to Kill Two Birds with One Stone: Learning to Rank with Multiple Objectives</a></li>
<li><a href="https://medium.com/swlh/rank-aware-recsys-evaluation-metrics-5191bba16832">MRR vs MAP vs NDCG: Rank-Aware Evaluation Metrics And When To Use Them</a></li>
<li><a href="https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html">Learning to rank introduction</a></li>
<li><a href="https://codemonk.in/blog/a-gentle-introduction-to-multi-objective-optimization/">A Gentle Introduction to Multi-Objective Optimisation</a></li>
<li><a href="https://www.gojek.io/blog/is-this-what-you-were-looking-for">Is This What You Were Looking For?</a></li>
<li><a href="https://www.techgistics.net/blog/2016/11/30/theuber-for-x-model-and-the-complexity-of-on-demand-delivery">The‚ÄúUber-for-X‚Äù Model and the Complexity of On-Demand Delivery</a></li>
<li><a href="https://www.gojek.io/blog/the-secret-sauce-behind-search-personalisation">The Secret Sauce Behind Search Personalisation</a></li>
<li><a href="https://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html">Mean Average Precision (MAP) For Recommender Systems</a></li>
<li><a href="https://home.uchicago.edu/~vlima/courses/econ201/Superstars.pdf">Superstar economics</a></li>
<li><a href="https://sites.google.com/view/kdd20-marketplace-autorecsys/">KDD 2020 Tutorial: Advances in Recommender Systems</a></li>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3523227.3547391">Timely Personalization at Peloton: A System and Algorithm for Boosting Time-Relevant Content</a></li>
<li><a href="https://relguzman.blogspot.com/2018/04/rejection-sampling-explained.html">Sampling: Rejection Sampling Explained</a></li>
<li><a href="http://orion.lcg.ufrj.br/Dr.Dobbs/books/book5/chap14.htm">Donna Harman‚Äôs Ranking Algorithms</a></li>
<li><a href="https://dl.acm.org/doi/abs/10.1145/3460231.3474610">Personalizing Peloton: Combining Rankers and Filters To Balance Engagement and Business Goals</a></li>
<li><a href="https://arxiv.org/ftp/arxiv/papers/2108/2108.06367.pdf">Multi-Objective Recommendations: A Tutorial</a></li>
<li><a href="https://www.onepeloton.com/press/articles/lessons-learned-from-building-context-aware-recommender-systems">Lessons Learned from Building out Context-Aware Recommender Systems</a></li>
<li><a href="https://www.onepeloton.com/press/articles/designing-an-early-stage-recommender-system">How We Built: An Early-Stage Recommender System</a></li>
<li><a href="https://engineering.fb.com/2020/12/10/web/how-instagram-suggests-new-content/">How Instagram suggests new content</a></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>