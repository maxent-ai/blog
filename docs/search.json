[
  {
    "objectID": "posts/post-1/rank-with-moo-1.html#stakeholders-objectives-the-objective-interplay",
    "href": "posts/post-1/rank-with-moo-1.html#stakeholders-objectives-the-objective-interplay",
    "title": "Rank, Rank & Rank: A Primer",
    "section": "Stakeholders, Objectives & the Objective interplay",
    "text": "Stakeholders, Objectives & the Objective interplay\nIn a multi-sided system with multiple objectives often the objectives interact and behave in different manners. At a high level, you could categorize the different types of these interplay as follows:\n\nCorrelated : Optimising for one objective helps the other.\nNeutral: Optimising for one does not impact the other\nAnti Correlated: Optimising for one hurts the other\n\nConsider the example of our Hypothetical on-demand delivery startup Hyper, which is a three-sided marketplace - i.e it has three sets of stakeholders with different motivations & objectives.\n\n\n\n\n\n\n\n\nStakeholder\nNeeds/Motivations\nPotential Objectives\n\n\n\n\nEnd User\nWants to order something from local partner shops.\n\nQuick delivery\nBest price\nReliable merchants\nFresh items\n\n\n\nMerchants\nProvide online visibility and find customers.\n\nMatching quality\nExposure\nMinimise wastage\n\n\n\nDelivery Partners\nEarn a stable livelihood.\n\nRegularity in jobs\nEarnings per partner\nEfficient drop location planning\n\n\n\n\nAs we see above each entity has a unique set of potential objectives one could optimise the recommendation system for & this has to be done in a deliberate and careful way or it might result in undesired outcomes.\n\n\n\n\n\n\nüßµ Superstar economics and towards a fair marketplace\n\n\n\n\n\nResearchers from Microsoft & Spotify found out that:\n\nRecommendation systems in general suffer from what is called as an inherent problem of ‚Äúsuperstar economics‚Äù: rankings have a top and a tail end, not just for popularity, but also for relevance. In an attempt to maximize user satisfaction, recommender system optimize for relevance. This inadvertently leads to lock-in of popular and relevant suppliers, especially for users who want to minimize the effort required to interact with the system. A major side-effect of the superstar economics is the impedance to suppliers on the tail-end of the spectrum, who struggle to attract consumers, given the low exposure, and thus, are not satisfied with the marketplace. Indeed, to continue to attract more suppliers to the platform, marketplaces face an interesting problem of optimizing their models for supplier exposure, and visibility. Indeed, the suppliers (e.g.¬†retailers, artists) would want a fair opportunity to be presented to the users.\n\nread more about this in Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness & Satisfaction in Recommendation Systems\n\n\n\nIn short, what a system optimises for is super important & in general, it needs to look for a balance while optimising for various objectives.\nBefore we proceed further on the track of optimising for multiple objectives (or multiple objective optimisation) - let us quickly visit how most modern recommendation systems look like & also do a quick recap of how one builds a model for ranking (aka Learning to rank) & some key metrics used for measuring these systems."
  },
  {
    "objectID": "posts/post-1/rank-with-moo-1.html#ranking-task",
    "href": "posts/post-1/rank-with-moo-1.html#ranking-task",
    "title": "Rank, Rank & Rank: A Primer",
    "section": "Ranking Task",
    "text": "Ranking Task\nGiven a query \\(q\\), and a set of \\(n\\) documents \\(D=d1,d2,...,dn\\), we‚Äôd like to learn a function \\(f\\) such that \\(f(q, D)\\) will predict the relevance of any given document associated with a query."
  },
  {
    "objectID": "posts/post-1/rank-with-moo-1.html#pointwise-method",
    "href": "posts/post-1/rank-with-moo-1.html#pointwise-method",
    "title": "Rank, Rank & Rank: A Primer",
    "section": "Pointwise method",
    "text": "Pointwise method\nIn pointwise method, the above ranking task is re-formulated as a standard classification/regression task. The function to be learned \\(f(q, D)\\) is simplified as \\(f(q, d_i)\\) i.e the relevance of each document given a query is scored independently.\nFor instance, if we have two queries associated with 2 and 3 resulting matched documents:\n\n\\(q_1 \\to d_1, d_2\\)\n\\(q_2 \\to d_3, d_4, d_5\\)\n\nThen the training data \\(x_i\\) in a pointwise method will essentially be every query-document pair as follows:\n\n\\(x_1 : q_1, d_1\\)\n\\(x_2 : q_1, d_2\\)\n\\(x_3 : q_2, d_3\\)\n\\(x_4 : q_2, d_4\\)\n\\(x_5 : q_2, d_5\\)\n\nSince each document is scored independently with the absolute relevance as the target label, the task is no different from any standard classification or regression task. As such any standard ml algorithms can be levergaed in this setting."
  },
  {
    "objectID": "posts/post-1/rank-with-moo-1.html#pairwise-method",
    "href": "posts/post-1/rank-with-moo-1.html#pairwise-method",
    "title": "Rank, Rank & Rank: A Primer",
    "section": "Pairwise method",
    "text": "Pairwise method\nIn pairwise method, the goal is to learn a pointwise scoring function \\(f(q, d_i)\\) similar to a pointwise formulation. However, the key difference arises in how the training data is consructed - where we take pairs of documents within the same query as training samples.\n\n\\(x_1 \\to q_1, (d_1, d_2)\\)\n\\(x_2 \\to q_1, (d_3, d_4)\\)\n\\(x_3 \\to q_1, (d_3, d_5)\\)\n\\(x_4 \\to q_1, (d_4, d_5)\\)\n\nIn this setting, a new set of pairwise binary labels are derived, by comapring the individual relevance score in each pair. For example, given the first query \\(q_1\\), if \\(y_1==\\) (i.e.. an irrelevant document) for \\(d_1\\) & \\(y_2=3\\) (i.e.. a Highly relevant document) for \\(d_2\\) then we can create a new label \\(y_1<y_2\\) for the pair of docs \\((d_1, d_2)\\) - by doing so we have essentially converted this back to a binary classification task again.\nNow in order to learn the function \\(f(q, d_i)\\) which is still pointwise, but in a pairwise manner, we model the difference in scores probablistically as follows:\n\\[\\begin{eqnarray} P(i>j) \\equiv \\frac{1}{1+exp^{-(s_i - s_j)}}\\end{eqnarray}\\]\ni.e, if document \\(i\\) is better matched than document \\(j\\) (denoted as \\(i>j\\)), then the probability of the scoring function to have scored \\(f(q, d_i) = S_i\\) should be close to 1. In other words, the model is trying to learn, given a query, how to score a pair of documents such that a more relevant document would be scored higher."
  },
  {
    "objectID": "posts/post-1/rank-with-moo-1.html#listwise-method",
    "href": "posts/post-1/rank-with-moo-1.html#listwise-method",
    "title": "Rank, Rank & Rank: A Primer",
    "section": "Listwise method",
    "text": "Listwise method\nListwise methods, solve the problem of ranking by learning to score the entire list jointly and they do so via two main sub techniques:\n\nDirect optimization of IR measures such as NDCG.(Eg: SoftRank, AdaRank).\nMinimize a loss function that is defined based on understanding the unique properties of the kind of ranking you are trying to achieve. (E.g. ListNet, ListMLE).\n\nLet‚Äôs do a quick review of one of these approaches:\nConsider ListNet, Which is based on the concept of permutation probability of a list of items. In this case we assume there is a pointwise scoring function \\(f(q,di)\\) used to score and rank a given list of items. But instead of modeling the probability as a pairwise comparison using scoring difference, we model the probability of the entire list of results. In this setting our documents and query dataset would appear like this:\n\n\\(x_1 : q_1, (d_1, d_2)\\)\n\\(x_2 : q_2, (d_3, d_4, d_5)\\)\n\nFirst let‚Äôs look at the Permutation probability. Let‚Äôs denote \\(œÄ\\) as a specific permutation of a given list of length \\(n\\), \\(\\Theta (s_i) = f(q, d_i)\\) as any increasing function of scoring \\(s_i\\) given a query \\(q\\) and a document \\(i\\). The probability of having a permutation \\(œÄ\\) can be written as follows:\n\\[\\begin{eqnarray} P(\\pi) = \\prod_{i=1}^n \\frac{\\phi(s_i)}{\\sum_{k=i}^n\\phi(s_k)} \\end{eqnarray}\\]\nTo illustrate consider a list of 3 items, then the probability of returning the permutation \\(s_1\\),\\(s_2\\),\\(s_3\\) is calculated as follows:\n\\[\\begin{eqnarray} P(\\pi = \\{s_1, s_2, s_3\\}) = \\frac{\\phi(s_1)}{\\phi(s_1) + \\phi(s_2) + \\phi(s_3)} \\cdot \\frac{\\phi(s_2)}{\\phi(s_2) + \\phi(s_3)} \\cdot \\frac{\\phi(s_3)}{\\phi(s_3)} \\end{eqnarray}\\]\nDue to computational complexity, ListNet simplies the problem by looking at only the top-one probability of a given item. The top-one probability of object i equals the sum of the permutation probabilities of permutations in which object i is ranked on the top. Indeed, the top-one probability of object i can be written as:\n\\[\\begin{eqnarray} P(i) = \\frac{\\phi(s_i)}{\\sum_{k=1}^n \\phi(s_k)} \\end{eqnarray}\\]\nGiven any two list of items represented by top-one probabilities, we can now measure the difference between them using cross entropy. Then we can use an ml algorithm which minimises that cross entropy. The choice of function \\(œï(‚ãÖ)\\), can be as simple as just an exponential function. When \\(œï(‚ãÖ)\\) is expotential and the list length is two, the solution basically reduces to a pairwise method as described earlier.\nWith that brief introduction out of the way, let‚Äôs also quickly look at the advantages and disadvantages of each of these approaches:\n\n\n\n\n\n\n\n\nMethod\nAdvantages\nDisadvantages\n\n\n\n\nPointwise\n\nSimplicity, Any standard ML models can be applied without any changes.\n\n\nThe results can be often sub-optimal due to not utilizing the full information of the entire list of matching documents for each query.\nThis requires explicit labels while constructing the dataset, and can be quite expensive.\n\n\n\nPairwise\n\nWe don‚Äôt need explicit labels, Only pairwise preferences are required.\nThe model learns how to rank directly, even though its a pairwise setting, but in theory it can approximate the performance of a general ranking task.\n\n\nThe Core Scoring mechanism is still pointwise. Hence, that relative information in the feature space among different documents given the same query is still not fully leveraged.\n\n\n\nListwise\n\nTheoretically this is a good solution for a ranking task.\n\n\nCostly to compute in its theoretical form and hence several approximations are used in practice.\nScoring function is still pointwise, which could be sub-optimal."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Part I - An Overview of Multiple Objective Optimisation for Ranking.\n\n\n\n\nltr\n\n\nrecsys\n\n\noptimisation\n\n\napplied-ml\n\n\nmarketplace\n\n\neconomics\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\nBharath G.S & Rita Anjana\n\n\n\n\n\n\nNo matching items"
  }
]